{
  "hash": "3b60ce6b131559a9f22c2643d678cee1",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: |\n  Convolutional \\\n  Neural Networks\nsubtitle: \"Image Classification with CIFAR\"\nformat:\n  revealjs:\n    width: 1200\n    scrollable: false\n    include-in-header: \"math.html\"\n    footer: m408.inqs.info/lectures/6a\n    theme: [default, styles.scss]\n    preview-links: true\n    navigation-mode: vertical\n    controls-layout: edges\n    controls-tutorial: true\n    slide-number: true\n    pointer:\n      pointerSize: 48\n    incremental: false \n    chalkboard:\n      theme: whiteboard\n      chalk-width: 4\nknitr:\n  opts_chunk: \n    echo: true\n    eval: false\n    message: false\n    warnings: false\n    comment: \"#>\" \n    \nrevealjs-plugins:\n  - pointer\n  - verticator\n  \nfilters: \n  - code-fullscreen\n  - reveal-auto-agenda\n\neditor: source\n---\n\n## R Packages\n\n```r\n# install.packages(\"tidyverse\")\n# install.packages(\"torch\")\n# install.packages(\"luz\")\n# install.packages(\"torchvision\")\n\nlibrary(torch)\nlibrary(luz) # high-level interface for torch\nlibrary(tidyverse)\nlibrary(torchvision) # for datasets and image transformation\n\n\n```\n\n## Python Data\n\n``` python\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\n\ntransform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\nbatch_size = 4\n\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n                                        download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n                                          shuffle=True, num_workers=2)\n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False,\n                                       download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n                                         shuffle=False, num_workers=2)\n\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n```\n\n# Image Classification\n\n## Image Classification\n\nImage classification is the process of having a computer analyzse an image and classify it with a selected category.\n\n## Image Classification\n\nWhat is this a picture of?\n\n::: fragment\n![](img/squirrel.jpg){fig-align=\"center\" width=\"500\"}\n:::\n\n## Image Classification\n\nHow did you know it was a squirrel?\n\n# Convolutional Neural Networks\n\n## Convolutional Neural Networks\n\nConvolutional Neural Networks became popular in the 2010's with the success of image classification.\n\n::: fragment\nThe idea is to mimic how a human mind will classify an image. (From an old understanding of neurobiology.)\n:::\n\n::: fragment\nWith the use of convolutional filters, a convolutional neural networks is trained by using a set of images that have been previously classfied.\n:::\n\n::: fragment\nOnce the network is trained, new images can be classified.\n:::\n\n## CNN\n\n![Credit: ISLR2](img/islr2/Chapter10/10_6.jpg){fig-align=\"center\"}\n\n## Architecture\n\n![](https://www.embedded.com/wp-content/uploads/2023/06/23026adi-cnn1_f03_thumb.jpg){fig-align=\"center\"}\n\n\n\n# Input Data\n\n## Input Data\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](6a_files/figure-revealjs/unnamed-chunk-1-1.png){width=960}\n:::\n:::\n\n\n## Channels\n \n\n::: {.cell}\n::: {.cell-output-display}\n![](6a_files/figure-revealjs/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n\n## Data - Red\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n#>             [,1]      [,2]       [,3]      [,4]      [,5]      [,6]      [,7]\n#>  [1,] 0.23137255 0.1686275 0.19607843 0.2666667 0.3843137 0.4666667 0.5450981\n#>  [2,] 0.06274510 0.0000000 0.07058824 0.2000000 0.3450980 0.4705882 0.5019608\n#>  [3,] 0.09803922 0.0627451 0.19215687 0.3254902 0.4313726 0.5058824 0.5098040\n#>  [4,] 0.12941177 0.1490196 0.34117648 0.4156863 0.4509804 0.4588235 0.4470588\n#>  [5,] 0.19607843 0.2313726 0.40000001 0.4980392 0.4862745 0.4745098 0.4705882\n#>  [6,] 0.27843139 0.3294118 0.43137255 0.5058824 0.5333334 0.5137255 0.5058824\n#>  [7,] 0.38039216 0.4352941 0.48235294 0.5098040 0.5333334 0.5176471 0.4784314\n#>  [8,] 0.45098040 0.4666667 0.50980395 0.5490196 0.5215687 0.4980392 0.5411765\n#>  [9,] 0.53725493 0.5019608 0.51764709 0.5019608 0.4666667 0.4823529 0.5019608\n#> [10,] 0.60392159 0.6039216 0.61176473 0.5490196 0.4823529 0.4901961 0.4941176\n#> [11,] 0.60392159 0.6078432 0.61176473 0.5764706 0.5215687 0.5372549 0.5450981\n#> [12,] 0.56862748 0.5725490 0.57254905 0.5294118 0.4980392 0.5058824 0.4588235\n#> [13,] 0.55686277 0.5529412 0.54901963 0.5647059 0.5764706 0.4745098 0.3294118\n#> [14,] 0.61960787 0.6039216 0.55686277 0.5607843 0.5176471 0.3529412 0.2823530\n#> [15,] 0.56862748 0.5843138 0.57647061 0.5764706 0.5333334 0.3137255 0.3490196\n#> [16,] 0.58039218 0.5725490 0.56862748 0.5764706 0.5215687 0.2470588 0.2588235\n#> [17,] 0.58431375 0.5607843 0.56470591 0.5921569 0.5176471 0.2509804 0.3294118\n#> [18,] 0.57647061 0.5254902 0.54901963 0.5803922 0.5294118 0.3921569 0.4235294\n#> [19,] 0.59607846 0.4588235 0.44705883 0.4823529 0.4941176 0.4784314 0.3647059\n#> [20,] 0.56862748 0.4980392 0.50196081 0.5215687 0.5176471 0.5294118 0.6705883\n#> [21,] 0.56078434 0.4980392 0.50588238 0.5058824 0.5098040 0.5490196 0.8588235\n#> [22,] 0.56078434 0.4901961 0.51372552 0.5019608 0.4823529 0.6000000 0.5803922\n#> [23,] 0.55294120 0.5137255 0.54509807 0.5450981 0.5411765 0.5921569 0.5019608\n#> [24,] 0.56078434 0.5450981 0.54117650 0.5843138 0.6274510 0.5882353 0.5764706\n#> [25,] 0.58431375 0.5215687 0.53333336 0.5764706 0.5882353 0.6000000 0.6156863\n#> [26,] 0.67450982 0.5647059 0.52941179 0.5333334 0.5294118 0.5450981 0.6000000\n#> [27,] 0.79215688 0.7333333 0.59215689 0.5019608 0.4784314 0.5254902 0.5568628\n#> [28,] 0.84705883 0.7568628 0.65882355 0.5921569 0.5137255 0.4941176 0.5411765\n#> [29,] 0.86274511 0.7882353 0.72941178 0.6745098 0.6117647 0.5568628 0.5568628\n#> [30,] 0.81568629 0.7882353 0.77647060 0.7490196 0.7176471 0.6705883 0.6235294\n#> [31,] 0.70588237 0.6784314 0.72941178 0.7607843 0.7764706 0.7882353 0.7411765\n#> [32,] 0.69411767 0.6588235 0.70196080 0.7372549 0.7921569 0.8549020 0.8549020\n#>            [,8]      [,9]     [,10]     [,11]     [,12]     [,13]     [,14]\n#>  [1,] 0.5686275 0.5843138 0.5843138 0.5137255 0.4901961 0.5568628 0.5647059\n#>  [2,] 0.4980392 0.4941176 0.4549020 0.4156863 0.3960784 0.4117647 0.4431373\n#>  [3,] 0.4745098 0.4431373 0.4392157 0.4392157 0.4156863 0.4117647 0.5019608\n#>  [4,] 0.4117647 0.4196078 0.4745098 0.4901961 0.4274510 0.4431373 0.5725490\n#>  [5,] 0.4470588 0.4196078 0.4901961 0.5058824 0.4156863 0.4235294 0.4862745\n#>  [6,] 0.4666667 0.4235294 0.4784314 0.4823529 0.4117647 0.4196078 0.4352941\n#>  [7,] 0.4745098 0.4980392 0.5411765 0.4862745 0.4705882 0.4196078 0.3137255\n#>  [8,] 0.5372549 0.5137255 0.5215687 0.5254902 0.4235294 0.2823530 0.2000000\n#>  [9,] 0.5098040 0.4745098 0.5372549 0.5137255 0.2901961 0.2117647 0.1960784\n#> [10,] 0.4980392 0.5215687 0.5176471 0.3529412 0.2470588 0.2431373 0.2745098\n#> [11,] 0.5254902 0.5529412 0.4745098 0.3137255 0.3803922 0.3529412 0.3843137\n#> [12,] 0.4039216 0.5098040 0.4705882 0.4352941 0.5725490 0.5333334 0.6392157\n#> [13,] 0.3450980 0.4274510 0.3960784 0.5411765 0.8352941 0.6980392 0.7490196\n#> [14,] 0.3176471 0.3294118 0.4196078 0.6470588 0.8980392 0.7176471 0.7490196\n#> [15,] 0.4117647 0.3764706 0.5058824 0.7529412 0.7254902 0.5686275 0.7960784\n#> [16,] 0.3450980 0.4431373 0.7137255 0.8627451 0.5411765 0.6352941 0.8078431\n#> [17,] 0.4392157 0.6392157 0.8745098 0.8078431 0.5686275 0.7686275 0.8000000\n#> [18,] 0.5647059 0.8235294 0.9725490 0.6862745 0.6862745 0.8627451 0.8862745\n#> [19,] 0.7019608 0.9333333 0.9725490 0.6666667 0.7254902 0.9450980 0.9019608\n#> [20,] 0.9294118 0.9882353 0.8980392 0.6784314 0.6627451 0.8627451 0.7607843\n#> [21,] 0.9568627 0.8235294 0.7568628 0.6509804 0.6000000 0.7490196 0.7019608\n#> [22,] 0.6509804 0.7372549 0.7137255 0.6705883 0.6470588 0.7647059 0.7450981\n#> [23,] 0.5333334 0.6862745 0.6784314 0.7411765 0.8039216 0.7882353 0.6588235\n#> [24,] 0.5921569 0.6627451 0.6549020 0.7019608 0.8313726 0.7960784 0.8117647\n#> [25,] 0.6352941 0.6862745 0.7450981 0.6509804 0.7921569 0.8784314 0.7725490\n#> [26,] 0.6392157 0.6509804 0.7215686 0.6509804 0.5882353 0.7215686 0.6117647\n#> [27,] 0.5882353 0.6000000 0.5803922 0.5294118 0.4980392 0.6000000 0.6509804\n#> [28,] 0.5647059 0.5568628 0.5372549 0.4705882 0.5137255 0.5686275 0.5647059\n#> [29,] 0.6000000 0.5882353 0.5450981 0.4941176 0.5333334 0.5803922 0.5529412\n#> [30,] 0.5764706 0.5294118 0.5098040 0.5450981 0.5764706 0.5647059 0.5686275\n#> [31,] 0.6784314 0.6117647 0.5450981 0.5568628 0.5686275 0.5529412 0.5529412\n#> [32,] 0.8117647 0.7490196 0.6862745 0.6509804 0.6392157 0.6392157 0.6313726\n#>           [,15]     [,16]     [,17]     [,18]     [,19]     [,20]     [,21]\n#>  [1,] 0.5372549 0.5058824 0.5372549 0.5254902 0.4862745 0.5450981 0.5450981\n#>  [2,] 0.4274510 0.4392157 0.4666667 0.4274510 0.4117647 0.4901961 0.4980392\n#>  [3,] 0.4862745 0.5098040 0.4980392 0.4784314 0.4509804 0.4705882 0.5098040\n#>  [4,] 0.5215687 0.4980392 0.4627451 0.4588235 0.4980392 0.4784314 0.5176471\n#>  [5,] 0.4745098 0.4235294 0.3843137 0.4313726 0.4588235 0.4705882 0.5254902\n#>  [6,] 0.4235294 0.3843137 0.3686275 0.3803922 0.3254902 0.3450980 0.4000000\n#>  [7,] 0.2666667 0.2901961 0.3960784 0.4117647 0.2549020 0.2274510 0.2470588\n#>  [8,] 0.1607843 0.2823530 0.7098039 0.8196079 0.4901961 0.2666667 0.2509804\n#>  [9,] 0.1725490 0.3372549 0.7960784 0.8509804 0.6352941 0.3921569 0.3019608\n#> [10,] 0.3098039 0.4039216 0.5960785 0.5803922 0.5529412 0.4745098 0.3960784\n#> [11,] 0.5372549 0.5450981 0.5803922 0.5254902 0.5411765 0.5254902 0.5490196\n#> [12,] 0.6627451 0.5960785 0.6313726 0.5803922 0.6941177 0.6313726 0.7647059\n#> [13,] 0.8274510 0.7411765 0.8039216 0.8117647 0.8352941 0.7490196 0.7803922\n#> [14,] 0.9372549 0.8588235 0.8941177 0.8823529 0.8392157 0.8470588 0.8235294\n#> [15,] 0.8745098 0.9490196 0.9568627 0.9333333 0.9450980 0.8901961 0.8823529\n#> [16,] 0.7686275 0.9686275 1.0000000 1.0000000 0.9607843 0.9254902 0.9019608\n#> [17,] 0.8627451 0.9529412 0.9607843 0.9372549 0.9176471 0.9058824 0.7647059\n#> [18,] 0.9019608 0.9137255 0.8784314 0.7882353 0.7215686 0.7098039 0.7450981\n#> [19,] 0.7333333 0.7058824 0.6509804 0.5725490 0.5843138 0.6156863 0.7215686\n#> [20,] 0.4823529 0.5294118 0.4980392 0.5921569 0.6470588 0.5176471 0.5921569\n#> [21,] 0.5019608 0.5764706 0.5843138 0.6745098 0.5764706 0.5019608 0.5529412\n#> [22,] 0.5960785 0.5607843 0.5960785 0.6000000 0.5568628 0.5529412 0.5294118\n#> [23,] 0.5921569 0.5686275 0.5725490 0.5843138 0.6000000 0.5843138 0.5647059\n#> [24,] 0.5843138 0.5450981 0.5647059 0.5372549 0.5921569 0.6078432 0.5960785\n#> [25,] 0.7529412 0.7058824 0.5725490 0.4941176 0.5529412 0.6117647 0.6000000\n#> [26,] 0.6196079 0.6588235 0.5843138 0.5294118 0.5098040 0.5176471 0.5019608\n#> [27,] 0.5607843 0.5098040 0.5019608 0.5921569 0.5960785 0.5294118 0.5450981\n#> [28,] 0.5372549 0.4980392 0.4941176 0.5450981 0.6000000 0.5843138 0.5490196\n#> [29,] 0.5137255 0.4941176 0.4980392 0.5411765 0.5882353 0.6039216 0.5843138\n#> [30,] 0.5372549 0.5333334 0.5372549 0.5803922 0.5960785 0.5882353 0.6078432\n#> [31,] 0.5450981 0.5490196 0.5607843 0.5450981 0.5411765 0.5607843 0.5725490\n#> [32,] 0.6000000 0.6235294 0.6352941 0.5843138 0.5490196 0.5803922 0.6313726\n#>           [,22]     [,23]     [,24]     [,25]     [,26]     [,27]     [,28]\n#>  [1,] 0.5215687 0.5333334 0.5450981 0.5960785 0.6392157 0.6588235 0.6235294\n#>  [2,] 0.4784314 0.5137255 0.4862745 0.4745098 0.5137255 0.5176471 0.5215687\n#>  [3,] 0.5137255 0.5450981 0.4980392 0.4941176 0.4980392 0.5098040 0.5568628\n#>  [4,] 0.5372549 0.5333334 0.5137255 0.4862745 0.5098040 0.5176471 0.5294118\n#>  [5,] 0.5490196 0.5137255 0.5529412 0.5294118 0.4980392 0.4745098 0.4666667\n#>  [6,] 0.3803922 0.3450980 0.4627451 0.5490196 0.5333334 0.4705882 0.4196078\n#>  [7,] 0.3058824 0.5333334 0.4784314 0.5450981 0.5921569 0.5058824 0.4235294\n#>  [8,] 0.3215686 0.4823529 0.4392157 0.5294118 0.5921569 0.5372549 0.4470588\n#>  [9,] 0.2941177 0.2901961 0.2980392 0.4196078 0.5294118 0.5294118 0.5058824\n#> [10,] 0.3764706 0.3372549 0.2941177 0.3960784 0.5333334 0.5333334 0.5254902\n#> [11,] 0.6862745 0.5568628 0.4000000 0.4235294 0.5294118 0.5137255 0.5215687\n#> [12,] 0.8196079 0.7411765 0.4901961 0.4235294 0.5490196 0.5372549 0.5176471\n#> [13,] 0.7372549 0.6313726 0.5098040 0.4862745 0.5137255 0.5098040 0.5137255\n#> [14,] 0.7843137 0.7411765 0.6823530 0.6313726 0.5450981 0.5254902 0.4941176\n#> [15,] 0.9215686 0.8588235 0.8784314 0.8431373 0.6117647 0.5019608 0.5058824\n#> [16,] 0.8431373 0.9058824 0.9803922 0.9450980 0.6196079 0.4901961 0.4941176\n#> [17,] 0.5882353 0.8156863 0.9803922 0.8901961 0.6392157 0.5686275 0.5607843\n#> [18,] 0.6666667 0.7019608 0.9058824 0.8745098 0.6352941 0.5725490 0.5490196\n#> [19,] 0.8470588 0.8313726 0.9254902 0.9254902 0.6509804 0.5333334 0.5254902\n#> [20,] 0.7921569 0.9411765 0.9411765 0.8705882 0.6117647 0.4666667 0.4705882\n#> [21,] 0.6784314 0.7921569 0.7450981 0.7764706 0.5960785 0.3921569 0.4274510\n#> [22,] 0.5333334 0.5803922 0.5529412 0.5529412 0.5411765 0.4352941 0.4352941\n#> [23,] 0.5647059 0.5686275 0.5607843 0.5058824 0.4823529 0.4862745 0.4431373\n#> [24,] 0.5490196 0.4196078 0.3568628 0.3294118 0.4117647 0.5176471 0.4627451\n#> [25,] 0.4509804 0.3019608 0.3098039 0.3647059 0.4941176 0.5215687 0.4666667\n#> [26,] 0.4980392 0.5294118 0.5607843 0.5450981 0.5333334 0.4980392 0.4745098\n#> [27,] 0.6078432 0.6313726 0.6039216 0.6039216 0.5607843 0.5098040 0.5176471\n#> [28,] 0.5294118 0.5764706 0.5803922 0.5843138 0.5843138 0.5372549 0.5607843\n#> [29,] 0.4862745 0.4941176 0.5529412 0.5686275 0.5764706 0.4980392 0.4470588\n#> [30,] 0.5411765 0.4705882 0.5019608 0.5568628 0.5294118 0.3529412 0.1960784\n#> [31,] 0.5294118 0.4588235 0.4392157 0.4784314 0.4078431 0.2274510 0.1333333\n#> [32,] 0.5647059 0.4392157 0.4666667 0.5098040 0.4705882 0.3607843 0.4039216\n#>           [,29]     [,30]     [,31]     [,32]\n#>  [1,] 0.6196079 0.6196079 0.5960785 0.5803922\n#>  [2,] 0.5215687 0.4823529 0.4666667 0.4784314\n#>  [3,] 0.5098040 0.4627451 0.4705882 0.4274510\n#>  [4,] 0.5098040 0.4901961 0.4745098 0.3686275\n#>  [5,] 0.4039216 0.3411765 0.2941177 0.2627451\n#>  [6,] 0.3450980 0.2627451 0.1372549 0.1254902\n#>  [7,] 0.3725490 0.3764706 0.3490196 0.2588235\n#>  [8,] 0.4117647 0.3960784 0.4941176 0.4000000\n#>  [9,] 0.4980392 0.4666667 0.4901961 0.5254902\n#> [10,] 0.5215687 0.5176471 0.5019608 0.5215687\n#> [11,] 0.5411765 0.5333334 0.5098040 0.5254902\n#> [12,] 0.5333334 0.5215687 0.5176471 0.5215687\n#> [13,] 0.5254902 0.5294118 0.5333334 0.5215687\n#> [14,] 0.5137255 0.5568628 0.5333334 0.5411765\n#> [15,] 0.5137255 0.5215687 0.5019608 0.5098040\n#> [16,] 0.4862745 0.4901961 0.4941176 0.4862745\n#> [17,] 0.5490196 0.5333334 0.4745098 0.4470588\n#> [18,] 0.5450981 0.5686275 0.5568628 0.5019608\n#> [19,] 0.5098040 0.4980392 0.5372549 0.5921569\n#> [20,] 0.4392157 0.3921569 0.3882353 0.5490196\n#> [21,] 0.4666667 0.4745098 0.4235294 0.5333334\n#> [22,] 0.4745098 0.5058824 0.5411765 0.7019608\n#> [23,] 0.4235294 0.4431373 0.5803922 0.7803922\n#> [24,] 0.3764706 0.4000000 0.6235294 0.7450981\n#> [25,] 0.4431373 0.5490196 0.7333333 0.6039216\n#> [26,] 0.5294118 0.7411765 0.8274510 0.5333334\n#> [27,] 0.6705883 0.8431373 0.7294118 0.4588235\n#> [28,] 0.7960784 0.8078431 0.4862745 0.2784314\n#> [29,] 0.7294118 0.6784314 0.2196078 0.1294118\n#> [30,] 0.5372549 0.6274510 0.2196078 0.2078431\n#> [31,] 0.5137255 0.7215686 0.3803922 0.3254902\n#> [32,] 0.6666667 0.8470588 0.5921569 0.4823529\n```\n\n\n:::\n:::\n\n\n\n# Convolutional Block\n\n## Convolutional Block\n\nA convolutional block (layer) is the process where a matrix (array) of data undergoes the following process.\n\n1. Apply a convolutional filter\n2. Fold the channels\n3. Pool the data\n\n## Convolution Filter\n\nA Convolution Filter will highlight certain features of an image.\n\n::: fragment\nThe matching features will contain a large value.\n:::\n\n::: fragment\nDismatching features will contain a smaller value.\n:::\n\n## Convolution Filter\n\n::: panel-tabset\n## Image\n\n$$\n\\left(\n\\begin{array}{ccc}\na & b & c \\\\\nd & e & f \\\\\ng & h & i \\\\\nj & k & l \n\\end{array}\n\\right)\n$$\n\n## Filter\n\n$$\n\\left(\n\\begin{array}{cc}\n\\alpha & \\beta \\\\\n\\gamma & \\delta\n\\end{array}\n\\right)\n$$\n\n## Both\n\n$$\n\\left(\n\\begin{array}{ccc}\na & b & c \\\\\nd & e & f \\\\\ng & h & i \\\\\nj & k & l \n\\end{array}\n\\right)\n*\n\\left(\n\\begin{array}{cc}\n\\alpha & \\beta \\\\\n\\gamma & \\delta\n\\end{array}\n\\right)\n$$\n\n## Results\n\n$$\n\\left(\n\\begin{array}{cc}\na\\alpha + b\\beta + d\\gamma + w\\delta & b\\alpha + c\\beta + e\\gamma + f\\delta \\\\\nd\\alpha + e\\beta + g\\gamma + h\\delta & e\\alpha + f\\beta + h\\gamma + i\\delta \\\\\ng\\alpha + h\\beta + j\\gamma + k\\delta & h\\alpha + i\\beta + k\\gamma + l\\delta\n\\end{array}\n\\right)\n$$\n:::\n\n\n## Data Example\n\n$$\n\\left(\n\\begin{array}{ccc}\n1 & 2 & 3 \\\\\n4 & 5 & 6 \\\\\n7 & 8 & 9 \n\\end{array}\n\\right)\n*\n\\left(\n\\begin{array}{cc}\n1/2 & 1/3 \\\\\n1/3 & 1/2\n\\end{array}\n\\right)\n$$\n\n$$\n\\left(\n\\begin{array}{cc}\n1/2 + 2/3 + 4/3 + 5/2 & 1 + 1 + 5/3 + 3  \\\\\n2 + 5/3 + 7/3 + 4 & 5/2 + 2 + 8/3 + 9/2\n\\end{array}\n\\right)\n$$\n\n## Folding\n\nFolding is the process when we combine channels together.\nIt is common to add the channels together once the convolution filter is applied to each one.\n\n## Folding Example\n\n\n$$\n\\left(\n\\begin{array}{cc}\n1 & 2  \\\\\n3 & 4 \n\\end{array}\n\\right)\n+\n\\left(\n\\begin{array}{cc}\n5 & 6 \\\\\n7 & 8\n\\end{array}\n\\right)\n+\n\\left(\n\\begin{array}{cc}\n9 & 10 \\\\\n11 & 12\n\\end{array}\n\\right)\n$$\n\n\n$$\n\\left(\n\\begin{array}{cc}\n15 & 18 \\\\\n21 & 24\n\\end{array}\n\\right)\n$$\n\n\n## Pooling Layers\n\nThe act of summarizing a large matrix to a smaller matrix.\n\n\n## Max Pool\n\n$$\n\\left[\n\\begin{array}{cccc}\n1 & 3 & 9 & 5 \\\\\n6 & 2 & 3 & 4 \\\\\n1 & 0 & 6 & 4 \\\\\n8 & 4 & 2 & 7\n\\end{array}\n\\right] \\rightarrow\n\\left[\n\\begin{array}{cc}\n6 & 9 \\\\\n8 & 7\n\\end{array}\n\\right]\n$$\n\n## Overall\n\n::: panel-tabset\n\n### Input\n\n$$\n\\left(\n\\begin{array}{ccc}\n1 & 2 & 3 \\\\\n4 & 5 & 6 \\\\\n7 & 8 & 9  \n\\end{array}\n\\right)\n$$\n\n$$\n\\left(\n\\begin{array}{ccc}\n1 & 2 & 3 \\\\\n4 & 5 & 6 \\\\\n7 & 8 & 9  \n\\end{array}\n\\right)\n$$\n\n$$\n\\left(\n\\begin{array}{ccc}\n1 & 2 & 3 \\\\\n4 & 5 & 6 \\\\\n7 & 8 & 9  \n\\end{array}\n\\right)\n$$\n\n\n### Filter\n\n$$\n\\left(\n\\begin{array}{ccc}\n1 & 2 & 3 \\\\\n4 & 5 & 6 \\\\\n7 & 8 & 9  \n\\end{array}\n\\right)\n*\n\\left(\n\\begin{array}{cc}\n\\alpha & \\beta \\\\\n\\gamma & \\delta\n\\end{array}\n\\right)\n$$\n\n$$\n\\left(\n\\begin{array}{ccc}\n10 & 20 & 30 \\\\\n40 & 50 & 60 \\\\\n70 & 80 & 90  \n\\end{array}\n\\right)\n*\n\\left(\n\\begin{array}{cc}\n\\alpha & \\beta \\\\\n\\gamma & \\delta\n\\end{array}\n\\right)\n$$\n\n\n$$\n\\left(\n\\begin{array}{ccc}\n100 & 200 & 300 \\\\\n400 & 500 & 600 \\\\\n700 & 800 & 900  \n\\end{array}\n\\right)\n*\n\\left(\n\\begin{array}{cc}\n\\alpha & \\beta \\\\\n\\gamma & \\delta\n\\end{array}\n\\right)\n$$\n\n\n\n### Fold\n\n$$\n\\left(\n\\begin{array}{cc}\n1 & 2  \\\\\n3 & 4 \n\\end{array}\n\\right)\n+\n\\left(\n\\begin{array}{cc}\n5 & 6 \\\\\n7 & 8\n\\end{array}\n\\right)\n+\n\\left(\n\\begin{array}{cc}\n9 & 10 \\\\\n11 & 12\n\\end{array}\n\\right)\n$$\n\n\n$$\n\\left(\n\\begin{array}{cc}\n15 & 18 \\\\\n21 & 24\n\\end{array}\n\\right)\n$$\n\n### Pool\n\n$$\n\\left[\n\\begin{array}{cccc}\n1 & 3 & 9 & 5 \\\\\n6 & 2 & 3 & 4 \\\\\n1 & 0 & 6 & 4 \\\\\n8 & 4 & 2 & 7\n\\end{array}\n\\right] \\rightarrow\n\\left[\n\\begin{array}{cc}\n6 & 9 \\\\\n8 & 7\n\\end{array}\n\\right]\n$$\n\n:::\n\n\n# CNN Architecture\n\n## Convolve Image\n\n## Flattening\n\nOnce the images has been pooled to a select pixels or features. The images are flattened to a set of inputs.\n\n::: fragment\nThese inputs are used to a traditional neural network to classify an image.\n:::\n\n## Training\n\nThe CNN is trained by supplying a set of pre-classified images.\n\n::: fragment\nThe parameters in the convolution filters are estimated using standard techniques.\n:::\n\n# R CIFAR Data Analysis\n\n## CIFAR-10 Data\n\nThe Canadian Institute for Advanced Research (CIFAR) provides a collection of 60,000 images that are classified in 10 categories. Each image has 32 by 32 pixels.\n\n## CIFAR-10 Classes\n\n::: {.columns}\n::: {.column}\n- airplanes\n- cars\n- birds\n- cats\n- deer\n:::\n::: {.column}\n- dogs\n- frogs\n- horses\n- ships\n- trucks\n:::\n:::\n\n## CIFAR-10 Example\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](6a_files/figure-revealjs/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n\n## Torch Packages in R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(torch)\nlibrary(luz)\nlibrary(torchvision)\nset.seed(909)\ntorch_manual_seed(909)\n```\n:::\n\n\n## CIFAR-10 Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndir <- \"../\"\n\n\ntrain_ds <- cifar10_dataset(\n  root = dir,\n  train = TRUE, \n  download = TRUE, \n  transform = transform_to_tensor\n)\n\ntest_ds <- cifar10_dataset(\n  dir, \n  train = FALSE, \n  download = TRUE,\n  transform = transform_to_tensor\n)\n\ntrain_dl <- dataloader(train_ds,\n  batch_size = 128,\n  shuffle = TRUE\n)\n```\n:::\n\n\n## Convolutional Block\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconv_block <- nn_module(\n  initialize = function(in_channels, out_channels) {\n    self$conv <- nn_conv2d(\n      in_channels = in_channels, \n      out_channels = out_channels, \n      kernel_size = c(3,3), \n      padding = \"same\"\n    )\n    self$relu <- nn_relu()\n    self$pool <- nn_max_pool2d(kernel_size = c(2,2))\n  },\n  forward = function(x) {\n    x |> \n      self$conv() |> \n      self$relu() |> \n      self$pool()\n  }\n)\n```\n:::\n\n\n## Model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel <- nn_module(\n  initialize = function() {\n    self$conv <- nn_sequential(\n      conv_block(3, 8),\n      conv_block(8, 16)\n    )\n    self$output <- nn_sequential(\n      nn_dropout(0.5),\n      nn_linear(1024, 16),\n      nn_relu(),\n      nn_linear(16, 10)\n    )\n  },\n  forward = function(x) {\n    x %>% \n      self$conv() |> \n      torch_flatten(start_dim = 2) |> \n      self$output()\n  }\n)\n```\n:::\n\n\n## Fitting Model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfitted <- model |> \n  setup(\n    loss = nn_cross_entropy_loss(),\n    optimizer = optim_rmsprop, \n  ) |> \n  set_opt_hparams(lr = 0.001) |> \n  fit(\n    train_dl,\n    epochs = 3\n  )\n```\n:::\n",
    "supporting": [
      "6a_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}