[
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Term: Spring 2026\nInstructor: Isaac Quintanilla Salinas\nContact: isaac.qs@csuci.edu\nOffice Location: Marin 2326\nOffice Hours:\n\nT/TH 1-2:30 PM\nWed 4-5 PM\n\nLecture: Gateway Hall 3501 T/TH 10:30 - 11:45 PM\nCourse Website: m408.inqs.info AND Canvas\n\n\n\nStudents will learn how to construct machine learning models using current data science programming languages. Topics will include nonparametric models, deep learning models, and neural networks. This is a programming intensive course.\n\n\n\n\nApply appropriate machine learning techniques given the data set and research goal.\nEvaluate model performance using standard methods such as cross-validation or simulation studies.\nDesign data workflows to execute machine learning algorithms using standard statistical software.\nBuild machine learning models to be used to predict outcomes from new observations of data.\n\n\n\n\nAll books should be available for free online:\n\nAn Introduction to Statistical Learning\n\nGareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani\nAvailable to download from the Broome Library\nwww.statlearning.com\n\nDeep Learning and Scientific Computing with R torch\n\nSigrid Keydana\nAvailable here: https://skeydan.github.io/Deep-Learning-and-Scientific-Computing-with-R-torch/\n\nPytorch Tutorials\n\nAvailable here: https://docs.pytorch.org/tutorials/index.html\n\nBayesian Statistical Modeling with Stan, R, and Python\n\nKentaro Matsuura\nAvailable for download from the Broome Library\n\nBayesian Data Analysis\n\nAndrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin\nAvailable here: https://sites.stat.columbia.edu/gelman/book/\n\nDeep Learning\n\nIan Goodfellow, Yoshua Bengio, and Aaron Courville\nAvailable here: https://www.deeplearningbook.org/\n\n\n\n\n\nFor this course, we will use several different statistical programs to analyze data and construct machine learning models. This course will primarily be taught and support R. However, students may complete assignments and projects in Python. Additionally, students are required to use Quarto, Torch, and Stan in the course. Lastly, students may use any IDE, but the course will only support Positron. All software is available for free. In class, we will download and setup your computing environment on your laptop with the following tools:\n\nQuarto is an open source scientific documentation system that allows you to embed code and text in one text file. More information can be found here: quarto.org\n\nWe will install this in class for R.\nComes Installed with Positron and RStudio\n\nStan is a Bayesian analysis software with Hamiltonian Monte Carlo Methods. More information can be found here: mc-stan.org\n\nWe will install this in class for R: cmdstanr.\nFor Python users: cmdstanpy\n\nTorch is a set of packages designed to develop and implement neural networks.\n\nWe will install this in class for R.\nMore information on torch for R: torch.mlverse.org\nMore information on torch for python: pytorch.org\n\n\n\n\n\nR (Recommended) is a statistical package that is available for download at: r-project.org.\nPython is a general programming langauge that is available to download at: python.org\n\nRecommend using tools to create python environments such as uv\n\n\n\n\n\n\nPositron (Recommended) provides free and open source tools for your data analysis in R and/or Python: positron.posit.co/download\n\nQuarto easily integrates with this IDE.\n\nRStudio provides free and open source tools for your data analysis in R: posit.co/download/rstudio-desktop/\nVS Code provides tools for software development as well as data analysis: code.visualstudio.com\nYou may use any other IDE that connects to R/Python, Torch, and Quarto.\n\n\n\n\n\n\n\n\nCategory\nPercentage\n\n\n\n\nAssignments\n50%\n\n\nFinal Project\n25%\n\n\nFinal Presentation\n25%\n\n\n\nAt the end of the quarter, course grades will be assigned according to the following scale:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA+\n98 – 100\nB+\n87 – &lt;90\nC+\n77 – &lt;80\nD+\n67 – &lt;70\n\n\n\n\nA\n93 – &lt;98\nB\n83 – &lt;87\nC\n73 – &lt;77\nD\n63 – &lt;67\nF\n&lt; 60\n\n\nA–\n90 - &lt;93\nB-\n80 – &lt;83\nC–\n70 – &lt;73\nD–\n60 – &lt;63\n\n\n\n\n\n\n\nAssignments will be assigned on a regular basis and posted here and Canvas. The homework is to help you practice the concepts learned in lecture and to help you study. You must turn in your own individual homework and show your understanding of the material. At the end of the semester, the two lowest homework grades will be dropped. Late work will be accepted, but with a 50% point penalty. The last day late work will be accepted is on DATE.\n\n\n\nThe final project and presentation will involve students to build a neural network to classify or predict an outcome of interest. You may use any data available to predict any outcome of interest. You may work individually or groups of 2. More information about the project and presentation will be available later in the semester.\n\n\n\nThere will be 3 extra credit opportunities worth a total of 5% of your overall grade. (There are no make-ups for missed extra credit assignments!) More information will be provided on the extra credit assignments on a later date. Information on the extra credit can be found here.\n\n\n\n\nThe following outline may be subject to change. Any changes will be announced in class.\n\n\n\nWeek\nTopic\n\n\n\n\n1\nIntro to Course/Computational Set Up\n\n\n2\nProgramming in R\n\n\n3\nModeling Data\n\n\n4\nNeural Networks\n\n\n5\nModules\n\n\n6\nConvolutional Neural Networks\n\n\n7\nRecurrent Neural Networks\n\n\n–\nSpring Break\n\n\n8\nGeneralizing Models\n\n\n9\nImage Classification\n\n\n10\nAudio Classification\n\n\n11\nBayesian Analysis\n\n\n12\nBayesian Linear Regression\n\n\n13\nBayesian Generalized Linear Models\n\n\n14\nBayesian Survival Analysis\n\n\n15\nFinal Presentation\n\n\n16\nFinal Presentation\n\n\n\n\n\n\nThe use of generative artificial intelligence (AI) in an ethical manner is permitted for this course.\n\n\nYou may use AI for:\n\nObtain clarification\nBrainstorming ideas, examples, outlines, and strategies\nGenerating questions for practice or exploration\nIdentifying keywords or phrasing to match professional goals\n\n\n\n\nYou may not:\n\nSubmit AI-generated work\nUse AI to complete assignments, quizzes, exams, or other assessments meant to reflect your own work\nUse AI to generate code\n\nAny AI-generated work will receive a 0 in the class. Severe cases will be reported to Academic Misconduct.\nYou may not upload any course material to any AI platforms such as ChatGPT, Claude, Meta AI, and Google Gemini. Exceptions are allowed for DASS-approved services."
  },
  {
    "objectID": "syllabus.html#math-408-machine-learning",
    "href": "syllabus.html#math-408-machine-learning",
    "title": "Syllabus",
    "section": "",
    "text": "Term: Spring 2026\nInstructor: Isaac Quintanilla Salinas\nContact: isaac.qs@csuci.edu\nOffice Location: Marin 2326\nOffice Hours:\n\nT/TH 1-2:30 PM\nWed 4-5 PM\n\nLecture: Gateway Hall 3501 T/TH 10:30 - 11:45 PM\nCourse Website: m408.inqs.info AND Canvas\n\n\n\nStudents will learn how to construct machine learning models using current data science programming languages. Topics will include nonparametric models, deep learning models, and neural networks. This is a programming intensive course.\n\n\n\n\nApply appropriate machine learning techniques given the data set and research goal.\nEvaluate model performance using standard methods such as cross-validation or simulation studies.\nDesign data workflows to execute machine learning algorithms using standard statistical software.\nBuild machine learning models to be used to predict outcomes from new observations of data.\n\n\n\n\nAll books should be available for free online:\n\nAn Introduction to Statistical Learning\n\nGareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani\nAvailable to download from the Broome Library\nwww.statlearning.com\n\nDeep Learning and Scientific Computing with R torch\n\nSigrid Keydana\nAvailable here: https://skeydan.github.io/Deep-Learning-and-Scientific-Computing-with-R-torch/\n\nPytorch Tutorials\n\nAvailable here: https://docs.pytorch.org/tutorials/index.html\n\nBayesian Statistical Modeling with Stan, R, and Python\n\nKentaro Matsuura\nAvailable for download from the Broome Library\n\nBayesian Data Analysis\n\nAndrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin\nAvailable here: https://sites.stat.columbia.edu/gelman/book/\n\nDeep Learning\n\nIan Goodfellow, Yoshua Bengio, and Aaron Courville\nAvailable here: https://www.deeplearningbook.org/\n\n\n\n\n\nFor this course, we will use several different statistical programs to analyze data and construct machine learning models. This course will primarily be taught and support R. However, students may complete assignments and projects in Python. Additionally, students are required to use Quarto, Torch, and Stan in the course. Lastly, students may use any IDE, but the course will only support Positron. All software is available for free. In class, we will download and setup your computing environment on your laptop with the following tools:\n\nQuarto is an open source scientific documentation system that allows you to embed code and text in one text file. More information can be found here: quarto.org\n\nWe will install this in class for R.\nComes Installed with Positron and RStudio\n\nStan is a Bayesian analysis software with Hamiltonian Monte Carlo Methods. More information can be found here: mc-stan.org\n\nWe will install this in class for R: cmdstanr.\nFor Python users: cmdstanpy\n\nTorch is a set of packages designed to develop and implement neural networks.\n\nWe will install this in class for R.\nMore information on torch for R: torch.mlverse.org\nMore information on torch for python: pytorch.org\n\n\n\n\n\nR (Recommended) is a statistical package that is available for download at: r-project.org.\nPython is a general programming langauge that is available to download at: python.org\n\nRecommend using tools to create python environments such as uv\n\n\n\n\n\n\nPositron (Recommended) provides free and open source tools for your data analysis in R and/or Python: positron.posit.co/download\n\nQuarto easily integrates with this IDE.\n\nRStudio provides free and open source tools for your data analysis in R: posit.co/download/rstudio-desktop/\nVS Code provides tools for software development as well as data analysis: code.visualstudio.com\nYou may use any other IDE that connects to R/Python, Torch, and Quarto.\n\n\n\n\n\n\n\n\nCategory\nPercentage\n\n\n\n\nAssignments\n50%\n\n\nFinal Project\n25%\n\n\nFinal Presentation\n25%\n\n\n\nAt the end of the quarter, course grades will be assigned according to the following scale:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA+\n98 – 100\nB+\n87 – &lt;90\nC+\n77 – &lt;80\nD+\n67 – &lt;70\n\n\n\n\nA\n93 – &lt;98\nB\n83 – &lt;87\nC\n73 – &lt;77\nD\n63 – &lt;67\nF\n&lt; 60\n\n\nA–\n90 - &lt;93\nB-\n80 – &lt;83\nC–\n70 – &lt;73\nD–\n60 – &lt;63\n\n\n\n\n\n\n\nAssignments will be assigned on a regular basis and posted here and Canvas. The homework is to help you practice the concepts learned in lecture and to help you study. You must turn in your own individual homework and show your understanding of the material. At the end of the semester, the two lowest homework grades will be dropped. Late work will be accepted, but with a 50% point penalty. The last day late work will be accepted is on DATE.\n\n\n\nThe final project and presentation will involve students to build a neural network to classify or predict an outcome of interest. You may use any data available to predict any outcome of interest. You may work individually or groups of 2. More information about the project and presentation will be available later in the semester.\n\n\n\nThere will be 3 extra credit opportunities worth a total of 5% of your overall grade. (There are no make-ups for missed extra credit assignments!) More information will be provided on the extra credit assignments on a later date. Information on the extra credit can be found here.\n\n\n\n\nThe following outline may be subject to change. Any changes will be announced in class.\n\n\n\nWeek\nTopic\n\n\n\n\n1\nIntro to Course/Computational Set Up\n\n\n2\nProgramming in R\n\n\n3\nModeling Data\n\n\n4\nNeural Networks\n\n\n5\nModules\n\n\n6\nConvolutional Neural Networks\n\n\n7\nRecurrent Neural Networks\n\n\n–\nSpring Break\n\n\n8\nGeneralizing Models\n\n\n9\nImage Classification\n\n\n10\nAudio Classification\n\n\n11\nBayesian Analysis\n\n\n12\nBayesian Linear Regression\n\n\n13\nBayesian Generalized Linear Models\n\n\n14\nBayesian Survival Analysis\n\n\n15\nFinal Presentation\n\n\n16\nFinal Presentation\n\n\n\n\n\n\nThe use of generative artificial intelligence (AI) in an ethical manner is permitted for this course.\n\n\nYou may use AI for:\n\nObtain clarification\nBrainstorming ideas, examples, outlines, and strategies\nGenerating questions for practice or exploration\nIdentifying keywords or phrasing to match professional goals\n\n\n\n\nYou may not:\n\nSubmit AI-generated work\nUse AI to complete assignments, quizzes, exams, or other assessments meant to reflect your own work\nUse AI to generate code\n\nAny AI-generated work will receive a 0 in the class. Severe cases will be reported to Academic Misconduct.\nYou may not upload any course material to any AI platforms such as ChatGPT, Claude, Meta AI, and Google Gemini. Exceptions are allowed for DASS-approved services."
  },
  {
    "objectID": "syllabus.html#university-policies",
    "href": "syllabus.html#university-policies",
    "title": "Syllabus",
    "section": "University Policies",
    "text": "University Policies\n\nSyllabus Policies and Assistance\nCSUCI’s Syllabus Policies and Assistance Website provides important details about academic policies, campus expectations, and student support services that are all highly applicable to your success as a student both in and outside of the classroom. Ensure that you review this site on a regular basis to stay informed about the policies and resources that support your success, as campus resources or policies may change semester to semester.\n\n\nAcademic Honesty\nConduct yourself with honesty and integrity. Do not submit others’ work as your own. Foassignments and quizzes that allow you to work with a group, only put your name on what the group submits if you genuinely contributed to the work. Work completely independently on exams, using only the materials that are indicated as allowed. Failure to observe academic honesty results in substantial penalties that can include failing the course.\n\n\nCSUCI Basic Need\nPlease use the link to the Basic Needs Program on the Syllabus Policies and Assistance website (&lt;go.csuci.edu/syllabuspolicies&gt;) for information on emergency food, housing accommodations, toiletries, and connections to critical resources.\n\n\nCSUCI Disability Statement\nIf you are a student with a disability requesting reasonable accommodations in this course, you need to contact Disability Accommodations and Support Services (DASS) located on the second floor of Arroyo Hall, via email accommodations@csuci.edu or call 805-437-3331. All requests for reasonable accommodations require registration with DASS in advance of need: https://www.csuci.edu/dass/students/apply-for-services.htm. Faculty, students and DASS will work together regarding classroom accommodations. You are encouraged to discuss approved.\n\n\nDisruption\n\nIf I Am Out: I will communicate via email and will hold classes asynchronously.\nIf You Are Out: Contact me as soon as possible to talk about your options. Reasonable accommodations will be provided for a brief absence. With proper documentation, extended accommodations will be provided."
  },
  {
    "objectID": "posts/week_2.html",
    "href": "posts/week_2.html",
    "title": "Week 2",
    "section": "",
    "text": "Welcome to the course!\n\n\n\n\n\nInstalling R and RStudio\nScripts\nR Calculator\nR Objects\nR Packages"
  },
  {
    "objectID": "posts/week_2.html#learning-outcomes",
    "href": "posts/week_2.html#learning-outcomes",
    "title": "Week 2",
    "section": "",
    "text": "Welcome to the course!\n\n\n\n\n\nInstalling R and RStudio\nScripts\nR Calculator\nR Objects\nR Packages"
  },
  {
    "objectID": "posts/week_2.html#resources",
    "href": "posts/week_2.html#resources",
    "title": "Week 2",
    "section": "Resources",
    "text": "Resources\n\n\n\nLecture\nSlides\nVideos\n\n\n\n\n1\nSlides\nNA\n\n\n2\nSlides\nNA"
  },
  {
    "objectID": "lectures/3b.html#r-packages",
    "href": "lectures/3b.html#r-packages",
    "title": "Optimization",
    "section": "R Packages",
    "text": "R Packages\n\nlibrary(tidyverse)\nlibrary(mvtnorm)\nlibrary(numDeriv)"
  },
  {
    "objectID": "lectures/3b.html#simulated-data",
    "href": "lectures/3b.html#simulated-data",
    "title": "Optimization",
    "section": "Simulated Data",
    "text": "Simulated Data\n\\[\nY_i = 3.85 + 12.3 X_1 - 9.7 X_2 + \\varepsilon_i\n\\]\n\\[\n\\varepsilon \\sim N(0, 2.4)\n\\]\n\nbeta &lt;- c(3.85, 12.3, -9.7)\nx &lt;- rmvnorm(500, c(3, 8))\nxx &lt;- cbind(1, x)\ny &lt;- xx%*%beta + rnorm(500, sd = sqrt(2.4))"
  },
  {
    "objectID": "lectures/3b.html#optimization-1",
    "href": "lectures/3b.html#optimization-1",
    "title": "Optimization",
    "section": "Optimization",
    "text": "Optimization"
  },
  {
    "objectID": "lectures/3b.html#gradient-descent-1",
    "href": "lectures/3b.html#gradient-descent-1",
    "title": "Optimization",
    "section": "Gradient Descent",
    "text": "Gradient Descent"
  },
  {
    "objectID": "lectures/3b.html#alternative-versions",
    "href": "lectures/3b.html#alternative-versions",
    "title": "Optimization",
    "section": "Alternative Versions",
    "text": "Alternative Versions"
  },
  {
    "objectID": "lectures/3b.html#stochastic-gradient-descent-1",
    "href": "lectures/3b.html#stochastic-gradient-descent-1",
    "title": "Optimization",
    "section": "Stochastic Gradient Descent",
    "text": "Stochastic Gradient Descent"
  },
  {
    "objectID": "lectures/3b.html#newton-raphson-algorithm",
    "href": "lectures/3b.html#newton-raphson-algorithm",
    "title": "Optimization",
    "section": "Newton-Raphson Algorithm",
    "text": "Newton-Raphson Algorithm"
  },
  {
    "objectID": "lectures/2b.html#r-packages",
    "href": "lectures/2b.html#r-packages",
    "title": "Torch",
    "section": "R Packages",
    "text": "R Packages\n\nlibrary(tidyverse)\nlibrary(torch)\nlibrary(mvtnorm)"
  },
  {
    "objectID": "lectures/2b.html#what-are-tensors",
    "href": "lectures/2b.html#what-are-tensors",
    "title": "Torch",
    "section": "What are Tensors?",
    "text": "What are Tensors?\n\n\n\n\n\nMathematics\n\n\nA tensor describes a relationship between algebraic objects.\n\n\n\n\n\n\n\nTorch\n\n\nAn n-dimensional array with optimized operations."
  },
  {
    "objectID": "lectures/2b.html#creating-tensors",
    "href": "lectures/2b.html#creating-tensors",
    "title": "Torch",
    "section": "Creating Tensors",
    "text": "Creating Tensors\n\nt1 &lt;- torch_tensor(matrix(1:9, ncol = 3))\nt2 &lt;- torch_tensor(1:3)\nt3 &lt;- torch_tensor(array(1:24, dim = c(4, 3, 2)))"
  },
  {
    "objectID": "lectures/2b.html#tensor-operations",
    "href": "lectures/2b.html#tensor-operations",
    "title": "Torch",
    "section": "Tensor Operations",
    "text": "Tensor Operations"
  },
  {
    "objectID": "lectures/2b.html#dimensions",
    "href": "lectures/2b.html#dimensions",
    "title": "Torch",
    "section": "Dimensions",
    "text": "Dimensions\n\nt1$shape\n\n#&gt; [1] 3 3\n\nt2$shape\n\n#&gt; [1] 3\n\nt3$shape\n\n#&gt; [1] 4 3 2"
  },
  {
    "objectID": "lectures/2b.html#type",
    "href": "lectures/2b.html#type",
    "title": "Torch",
    "section": "Type",
    "text": "Type\n\nt1$dtype\n\n#&gt; torch_Long\n\nt2$dtype\n\n#&gt; torch_Long\n\nt3$dtype\n\n#&gt; torch_Long"
  },
  {
    "objectID": "lectures/2b.html#changing-type",
    "href": "lectures/2b.html#changing-type",
    "title": "Torch",
    "section": "Changing Type",
    "text": "Changing Type\n\nt1$to(dtype = torch_float())\n\n#&gt; torch_tensor\n#&gt;  1  4  7\n#&gt;  2  5  8\n#&gt;  3  6  9\n#&gt; [ CPUFloatType{3,3} ]\n\nt2$to(dtype = torch_float())\n\n#&gt; torch_tensor\n#&gt;  1\n#&gt;  2\n#&gt;  3\n#&gt; [ CPUFloatType{3} ]\n\nt3$to(dtype = torch_float())\n\n#&gt; torch_tensor\n#&gt; (1,.,.) = \n#&gt;    1  13\n#&gt;    5  17\n#&gt;    9  21\n#&gt; \n#&gt; (2,.,.) = \n#&gt;    2  14\n#&gt;    6  18\n#&gt;   10  22\n#&gt; \n#&gt; (3,.,.) = \n#&gt;    3  15\n#&gt;    7  19\n#&gt;   11  23\n#&gt; \n#&gt; (4,.,.) = \n#&gt;    4  16\n#&gt;    8  20\n#&gt;   12  24\n#&gt; [ CPUFloatType{4,3,2} ]"
  },
  {
    "objectID": "lectures/2b.html#set-type",
    "href": "lectures/2b.html#set-type",
    "title": "Torch",
    "section": "Set Type",
    "text": "Set Type\n\nt1 &lt;- torch_tensor(matrix(1:9, ncol = 3), dtype = torch_float())\nt2 &lt;- torch_tensor(1:3, dtype = torch_float())\nt3 &lt;- torch_tensor(array(1:24, dim = c(4, 3, 2)), dtype = torch_float())"
  },
  {
    "objectID": "lectures/2b.html#device",
    "href": "lectures/2b.html#device",
    "title": "Torch",
    "section": "Device",
    "text": "Device\n\nt1$device\n\n#&gt; torch_device(type='cpu')\n\nt2$device\n\n#&gt; torch_device(type='cpu')\n\nt3$device\n\n#&gt; torch_device(type='cpu')"
  },
  {
    "objectID": "lectures/2b.html#set-device",
    "href": "lectures/2b.html#set-device",
    "title": "Torch",
    "section": "Set Device",
    "text": "Set Device\nt1 &lt;- torch_tensor(matrix(1:9, ncol = 3), device = \"cuda\")\nt2 &lt;- torch_tensor(1:3, device = \"cuda\")\nt3 &lt;- torch_tensor(array(1:24, dim = c(4, 3, 2)), device = \"cuda\")\n\n\n\n\n\n\nNote\n\n\nUse if cuda is installed (Nvidia users)"
  },
  {
    "objectID": "lectures/2b.html#vectors",
    "href": "lectures/2b.html#vectors",
    "title": "Torch",
    "section": "Vectors",
    "text": "Vectors\n\nt1 &lt;- torch_tensor(1:6)\nt2 &lt;- torch_tensor(7:12)\nt3 &lt;- torch_tensor(1:3)\nt1; t2; t3\n\n#&gt; torch_tensor\n#&gt;  1\n#&gt;  2\n#&gt;  3\n#&gt;  4\n#&gt;  5\n#&gt;  6\n#&gt; [ CPULongType{6} ]\n\n\n#&gt; torch_tensor\n#&gt;   7\n#&gt;   8\n#&gt;   9\n#&gt;  10\n#&gt;  11\n#&gt;  12\n#&gt; [ CPULongType{6} ]\n\n\n#&gt; torch_tensor\n#&gt;  1\n#&gt;  2\n#&gt;  3\n#&gt; [ CPULongType{3} ]"
  },
  {
    "objectID": "lectures/2b.html#additionsubtraction",
    "href": "lectures/2b.html#additionsubtraction",
    "title": "Torch",
    "section": "Addition/Subtraction",
    "text": "Addition/Subtraction\n\nt1$add(t2)\n\n#&gt; torch_tensor\n#&gt;   8\n#&gt;  10\n#&gt;  12\n#&gt;  14\n#&gt;  16\n#&gt;  18\n#&gt; [ CPULongType{6} ]"
  },
  {
    "objectID": "lectures/2b.html#scalar-multiplication",
    "href": "lectures/2b.html#scalar-multiplication",
    "title": "Torch",
    "section": "Scalar Multiplication",
    "text": "Scalar Multiplication\n\n10*t1\n\n#&gt; torch_tensor\n#&gt;  10\n#&gt;  20\n#&gt;  30\n#&gt;  40\n#&gt;  50\n#&gt;  60\n#&gt; [ CPUFloatType{6} ]"
  },
  {
    "objectID": "lectures/2b.html#elementwise-multiplication",
    "href": "lectures/2b.html#elementwise-multiplication",
    "title": "Torch",
    "section": "Elementwise Multiplication",
    "text": "Elementwise Multiplication\n\nt1$multiply(t2)\n\n#&gt; torch_tensor\n#&gt;   7\n#&gt;  16\n#&gt;  27\n#&gt;  40\n#&gt;  55\n#&gt;  72\n#&gt; [ CPULongType{6} ]"
  },
  {
    "objectID": "lectures/2b.html#dot-product",
    "href": "lectures/2b.html#dot-product",
    "title": "Torch",
    "section": "Dot Product",
    "text": "Dot Product\n\nt1$dot(t2)\n\n#&gt; torch_tensor\n#&gt; 217\n#&gt; [ CPULongType{} ]"
  },
  {
    "objectID": "lectures/2b.html#matrix",
    "href": "lectures/2b.html#matrix",
    "title": "Torch",
    "section": "Matrix",
    "text": "Matrix\n\nt1 &lt;- torch_tensor(matrix(1:9, ncol = 3), dtype = torch_float())\nt2 &lt;- torch_tensor(matrix(rpois(9, 3), ncol = 3), dtype = torch_float())\nt3 &lt;- torch_tensor(matrix(1:3, nrow = 3), dtype = torch_float())\n\nt1; t2; t3\n\n#&gt; torch_tensor\n#&gt;  1  4  7\n#&gt;  2  5  8\n#&gt;  3  6  9\n#&gt; [ CPUFloatType{3,3} ]\n\n\n#&gt; torch_tensor\n#&gt;  2  4  4\n#&gt;  4  3  3\n#&gt;  3  2  4\n#&gt; [ CPUFloatType{3,3} ]\n\n\n#&gt; torch_tensor\n#&gt;  1\n#&gt;  2\n#&gt;  3\n#&gt; [ CPUFloatType{3,1} ]"
  },
  {
    "objectID": "lectures/2b.html#transpose",
    "href": "lectures/2b.html#transpose",
    "title": "Torch",
    "section": "Transpose",
    "text": "Transpose\n\nt1$t()\n\n#&gt; torch_tensor\n#&gt;  1  2  3\n#&gt;  4  5  6\n#&gt;  7  8  9\n#&gt; [ CPUFloatType{3,3} ]\n\nt2$t()\n\n#&gt; torch_tensor\n#&gt;  2  4  3\n#&gt;  4  3  2\n#&gt;  4  3  4\n#&gt; [ CPUFloatType{3,3} ]\n\nt3$t()\n\n#&gt; torch_tensor\n#&gt;  1  2  3\n#&gt; [ CPUFloatType{1,3} ]"
  },
  {
    "objectID": "lectures/2b.html#additionsubtraction-1",
    "href": "lectures/2b.html#additionsubtraction-1",
    "title": "Torch",
    "section": "Addition/Subtraction",
    "text": "Addition/Subtraction\nMore information on matrix arithmetic can be found here.\n\nt1$add(t2)\n\n#&gt; torch_tensor\n#&gt;   3   8  11\n#&gt;   6   8  11\n#&gt;   6   8  13\n#&gt; [ CPUFloatType{3,3} ]\n\nt1$subtract(t2)\n\n#&gt; torch_tensor\n#&gt; -1  0  3\n#&gt; -2  2  5\n#&gt;  0  4  5\n#&gt; [ CPUFloatType{3,3} ]"
  },
  {
    "objectID": "lectures/2b.html#scalar-multiplication-1",
    "href": "lectures/2b.html#scalar-multiplication-1",
    "title": "Torch",
    "section": "Scalar Multiplication",
    "text": "Scalar Multiplication\n\n10*t1\n\n#&gt; torch_tensor\n#&gt;  10  40  70\n#&gt;  20  50  80\n#&gt;  30  60  90\n#&gt; [ CPUFloatType{3,3} ]"
  },
  {
    "objectID": "lectures/2b.html#element-wise-multiplications",
    "href": "lectures/2b.html#element-wise-multiplications",
    "title": "Torch",
    "section": "Element-wise Multiplications",
    "text": "Element-wise Multiplications\n\nt1; t2\n\n#&gt; torch_tensor\n#&gt;  1  4  7\n#&gt;  2  5  8\n#&gt;  3  6  9\n#&gt; [ CPUFloatType{3,3} ]\n\n\n#&gt; torch_tensor\n#&gt;  2  4  4\n#&gt;  4  3  3\n#&gt;  3  2  4\n#&gt; [ CPUFloatType{3,3} ]\n\nt1$multiply(t2)\n\n#&gt; torch_tensor\n#&gt;   2  16  28\n#&gt;   8  15  24\n#&gt;   9  12  36\n#&gt; [ CPUFloatType{3,3} ]"
  },
  {
    "objectID": "lectures/2b.html#matrix-multiplication",
    "href": "lectures/2b.html#matrix-multiplication",
    "title": "Torch",
    "section": "Matrix Multiplication",
    "text": "Matrix Multiplication\nMore information on matrix multiplication can be found here.\n\nt1$matmul(t2)\n\n#&gt; torch_tensor\n#&gt;  39  30  44\n#&gt;  48  39  55\n#&gt;  57  48  66\n#&gt; [ CPUFloatType{3,3} ]\n\nt2$matmul(t1)\n\n#&gt; torch_tensor\n#&gt;  22  52  82\n#&gt;  19  49  79\n#&gt;  19  46  73\n#&gt; [ CPUFloatType{3,3} ]\n\nt3$t()$matmul(t1)\n\n#&gt; torch_tensor\n#&gt;  14  32  50\n#&gt; [ CPUFloatType{1,3} ]"
  },
  {
    "objectID": "lectures/2b.html#determinant",
    "href": "lectures/2b.html#determinant",
    "title": "Torch",
    "section": "Determinant",
    "text": "Determinant\n\nt1$det()\n\n#&gt; torch_tensor\n#&gt; 0\n#&gt; [ CPUFloatType{} ]"
  },
  {
    "objectID": "lectures/2b.html#inverse",
    "href": "lectures/2b.html#inverse",
    "title": "Torch",
    "section": "Inverse",
    "text": "Inverse\n\nt2$inverse()\n\n#&gt; torch_tensor\n#&gt; -0.3000  0.4000  0.0000\n#&gt;  0.3500  0.2000 -0.5000\n#&gt;  0.0500 -0.4000  0.5000\n#&gt; [ CPUFloatType{3,3} ]"
  },
  {
    "objectID": "lectures/2b.html#diagonal-elements",
    "href": "lectures/2b.html#diagonal-elements",
    "title": "Torch",
    "section": "Diagonal Elements",
    "text": "Diagonal Elements\n\nt1$diag()\n\n#&gt; torch_tensor\n#&gt;  1\n#&gt;  5\n#&gt;  9\n#&gt; [ CPUFloatType{3} ]\n\ntorch_diag(1:3)\n\n#&gt; torch_tensor\n#&gt;  1  0  0\n#&gt;  0  2  0\n#&gt;  0  0  3\n#&gt; [ CPULongType{3,3} ]"
  },
  {
    "objectID": "lectures/2b.html#matrix-of-01",
    "href": "lectures/2b.html#matrix-of-01",
    "title": "Torch",
    "section": "Matrix of 0/1",
    "text": "Matrix of 0/1\n\ntorch_zeros(3,3)\n\n#&gt; torch_tensor\n#&gt;  0  0  0\n#&gt;  0  0  0\n#&gt;  0  0  0\n#&gt; [ CPUFloatType{3,3} ]\n\ntorch_ones(2,3)\n\n#&gt; torch_tensor\n#&gt;  1  1  1\n#&gt;  1  1  1\n#&gt; [ CPUFloatType{2,3} ]"
  },
  {
    "objectID": "lectures/2b.html#identity-matrix",
    "href": "lectures/2b.html#identity-matrix",
    "title": "Torch",
    "section": "Identity Matrix",
    "text": "Identity Matrix\n\ntorch_eye(n = 4)\n\n#&gt; torch_tensor\n#&gt;  1  0  0  0\n#&gt;  0  1  0  0\n#&gt;  0  0  1  0\n#&gt;  0  0  0  1\n#&gt; [ CPUFloatType{4,4} ]"
  },
  {
    "objectID": "lectures/2b.html#linear-regression-1",
    "href": "lectures/2b.html#linear-regression-1",
    "title": "Torch",
    "section": "Linear Regression",
    "text": "Linear Regression\n\\[\nY_i = 3.85 + 12.3 X_1 - 9.7 X_2 + \\varepsilon_i\n\\]\n\\[\n\\varepsilon \\sim N(0, 2.4)\n\\]\n\nbeta &lt;- c(3.85, 12.3, -9.7)\nx &lt;- rmvnorm(500, c(3, 8))\nxx &lt;- cbind(1, x)\ny &lt;- xx%*%beta + rnorm(500, sd = sqrt(2.4))"
  },
  {
    "objectID": "lectures/2b.html#ols-estimator",
    "href": "lectures/2b.html#ols-estimator",
    "title": "Torch",
    "section": "OLS Estimator",
    "text": "OLS Estimator\n\\[\n\\hat\\bbeta = (\\bX^\\mrT\\bX)\\inv\\bX^\\mrT\\bY\n\\]\n\n\n\\[\n\\bX =\\left(\n\\begin{array}{ccc}\n1 & X_{1,1} & X_{2,1} \\\\\n1 & X_{1,2} & X_{2,2} \\\\\n\\vdots & \\vdots & \\vdots \\\\\n1 & X_{1,500} & X_{2,500} \\\\\n\\end{array}\n\\right)\n\\]\n\n\\[\n\\bY =\\left(\n\\begin{array}{ccc}\nY_1 \\\\\nY_2 \\\\\n\\vdots \\\\\nY_{500}\n\\end{array}\n\\right)\n\\]"
  },
  {
    "objectID": "lectures/2b.html#using-r",
    "href": "lectures/2b.html#using-r",
    "title": "Torch",
    "section": "Using R",
    "text": "Using R\n\\[\n\\hat\\bbeta = (\\bX^\\mrT\\bX)\\inv\\bX^\\mrT\\bY\n\\]\n\nlm(y ~ x)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = y ~ x)\n#&gt; \n#&gt; Coefficients:\n#&gt; (Intercept)           x1           x2  \n#&gt;       3.826       12.258       -9.690\n\nsolve(t(xx)%*%xx)%*%t(xx)%*%y\n\n#&gt;           [,1]\n#&gt; [1,]  3.825633\n#&gt; [2,] 12.257655\n#&gt; [3,] -9.690359"
  },
  {
    "objectID": "lectures/2b.html#using-torch",
    "href": "lectures/2b.html#using-torch",
    "title": "Torch",
    "section": "Using torch",
    "text": "Using torch\n\\[\n\\hat\\bbeta = (\\bX^\\mrT\\bX)\\inv\\bX^\\mrT\\bY\n\\]\n\nxxt &lt;- torch_tensor(xx)\nyt &lt;- torch_tensor(y)\n\nxxt$t()$matmul(xxt)$inverse()$matmul(xxt$t())$matmul(yt)\n\n#&gt; torch_tensor\n#&gt;   3.8235\n#&gt;  12.2576\n#&gt;  -9.6900\n#&gt; [ CPUFloatType{3,1} ]"
  },
  {
    "objectID": "lectures/1b.html#r-programming",
    "href": "lectures/1b.html#r-programming",
    "title": "Computational Setup",
    "section": "R Programming",
    "text": "R Programming\nR is a statistical programming package that allows you to conduct different types of analysis.\nR\n\n\n\n\n\n\nWindows Users\n\n\nInstall RTools"
  },
  {
    "objectID": "lectures/1b.html#positron",
    "href": "lectures/1b.html#positron",
    "title": "Computational Setup",
    "section": "Positron",
    "text": "Positron\nA piece of software that organizes how you conduct statistical analysis in R.\nPositron\n\n\n\n\n\n\nWindows Users\n\n\nUse system-level package If you cannot work with R, install Visual C++ Redistributable"
  },
  {
    "objectID": "lectures/1b.html#rstudio",
    "href": "lectures/1b.html#rstudio",
    "title": "Computational Setup",
    "section": "RStudio",
    "text": "RStudio\nIf Positron does not work, install RStudio instead."
  },
  {
    "objectID": "lectures/1b.html#installing-torch",
    "href": "lectures/1b.html#installing-torch",
    "title": "Computational Setup",
    "section": "Installing Torch",
    "text": "Installing Torch\nIn R, install torch with:\ninstall.packages(\"torch\")\n\n\n\n\n\n\nNvidia-Users\n\n\noptions(timeout = 600) # increasing timeout is recommended since we will be downloading a 2GB file.\n# For Windows and Linux: \"cpu\", \"cu128\" are the only currently supported\n# For MacOS the supported are: \"cpu-intel\" or \"cpu-m1\"\nkind &lt;- \"cpu\"\nversion &lt;- available.packages()[\"torch\",\"Version\"]\noptions(repos = c(\n  torch = sprintf(\"https://torch-cdn.mlverse.org/packages/%s/%s/\", kind, version),\n  CRAN = \"https://cloud.r-project.org\" # or any other from which you want to install the other R dependencies.\n))\ninstall.packages(\"torch\")"
  },
  {
    "objectID": "lectures/1b.html#installing-stan",
    "href": "lectures/1b.html#installing-stan",
    "title": "Computational Setup",
    "section": "Installing Stan",
    "text": "Installing Stan\ninstall.packages(\"cmdstanr\", \n    repos = c('https://stan-dev.r-universe.dev', getOption(\"repos\")))\ncmdstanr::check_cmdstan_toolchain()\ncmdstanr::install_cmdstan(cores = 2)"
  },
  {
    "objectID": "lectures/1b.html#other-r-packages",
    "href": "lectures/1b.html#other-r-packages",
    "title": "Computational Setup",
    "section": "Other R Packages",
    "text": "Other R Packages\n\nCore PackagesCourse PackagesMisc Packages\n\n\n\nTidyverse\n\n\n\n\nmvtnorm\nluz\n\n\n\n\n\n\n\nNote\n\n\nMore packages will be added throughout the course if necessary.\n\n\n\n\n\n\nRMarkdown\nQuarto\nextraInserts (GitHub Package)"
  },
  {
    "objectID": "lectures/1b.html#load-r-package",
    "href": "lectures/1b.html#load-r-package",
    "title": "Computational Setup",
    "section": "Load R Package",
    "text": "Load R Package\nlibrary(tidyverse)\nlibrary(torch)\n\nYou must load packages every new R Session"
  },
  {
    "objectID": "lectures/1b.html#workspaces-1",
    "href": "lectures/1b.html#workspaces-1",
    "title": "Computational Setup",
    "section": "Workspaces",
    "text": "Workspaces\nWorkspaces allows you to create locations on your computer and set up a computing environment in one location."
  },
  {
    "objectID": "lectures/1b.html#r-as-a-calculator",
    "href": "lectures/1b.html#r-as-a-calculator",
    "title": "Computational Setup",
    "section": "R as a calculator",
    "text": "R as a calculator\nR can evaluate different expressions in the console tab.\nTry the following:\n\n\\(4(4+2)/34\\)\n\\(6^3\\)\n\\(3-1\\)\n\\(4+4/3+45(32*34-54)\\)"
  },
  {
    "objectID": "lectures/1b.html#r-functions",
    "href": "lectures/1b.html#r-functions",
    "title": "Computational Setup",
    "section": "R Functions",
    "text": "R Functions\nR functions performs tasks to specific data values.\nEvaluate the following values in R:\n\n\\(\\sqrt{3}\\)\n\\(e^3\\)\n\\(\\ln(53)\\)\n\\(\\log(324)\\)\n\\(\\sin(3)\\)\n\\(\\sin(3\\pi)\\)"
  },
  {
    "objectID": "lectures/1b.html#types-of-data",
    "href": "lectures/1b.html#types-of-data",
    "title": "Computational Setup",
    "section": "Types of Data",
    "text": "Types of Data\n\nNumeric\nCharacter\nLogical\nMissing\n\nEvaluate the following code:\nis.numeric(1)\nis.numeric(\"1\")\nis.numeric(T)\nis.numeric(NA)"
  },
  {
    "objectID": "lectures/1b.html#types-of-objects",
    "href": "lectures/1b.html#types-of-objects",
    "title": "Computational Setup",
    "section": "Types of Objects",
    "text": "Types of Objects\nIn R, an object contains a set of data. The most common types are vectors and matrix.\nRun this code and print out the objects in the console:\nx &lt;- 3:34\ny &lt;- matrix(1:20, nrow = 4)"
  },
  {
    "objectID": "lectures/1b.html#data-frames",
    "href": "lectures/1b.html#data-frames",
    "title": "Computational Setup",
    "section": "Data Frames",
    "text": "Data Frames\nData frames can be thought of as R’s version of a data set.\nPlay around with mtcars:\n\n\nCode\nmtcars \n\n\n#&gt;                      mpg cyl  disp  hp drat    wt  qsec vs am gear carb\n#&gt; Mazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\n#&gt; Mazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\n#&gt; Datsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\n#&gt; Hornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\n#&gt; Hornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\n#&gt; Valiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\n#&gt; Duster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\n#&gt; Merc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\n#&gt; Merc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\n#&gt; Merc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\n#&gt; Merc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\n#&gt; Merc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\n#&gt; Merc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\n#&gt; Merc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\n#&gt; Cadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\n#&gt; Lincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\n#&gt; Chrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\n#&gt; Fiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\n#&gt; Honda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\n#&gt; Toyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\n#&gt; Toyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\n#&gt; Dodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\n#&gt; AMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\n#&gt; Camaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\n#&gt; Pontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\n#&gt; Fiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\n#&gt; Porsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\n#&gt; Lotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\n#&gt; Ford Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\n#&gt; Ferrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\n#&gt; Maserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\n#&gt; Volvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2"
  },
  {
    "objectID": "lectures/1b.html#lists",
    "href": "lectures/1b.html#lists",
    "title": "Computational Setup",
    "section": "Lists",
    "text": "Lists\nList can be thought as an extended vector, but each element is a different R object.\nTry playing with this R object:\n\n\nCode\nlist_one &lt;- list(mtcars, rep(0, 4),\n                 diag(rep(1, 3)))\nlist_one\n\n\n#&gt; [[1]]\n#&gt;                      mpg cyl  disp  hp drat    wt  qsec vs am gear carb\n#&gt; Mazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\n#&gt; Mazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\n#&gt; Datsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\n#&gt; Hornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\n#&gt; Hornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\n#&gt; Valiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\n#&gt; Duster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\n#&gt; Merc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\n#&gt; Merc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\n#&gt; Merc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\n#&gt; Merc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\n#&gt; Merc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\n#&gt; Merc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\n#&gt; Merc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\n#&gt; Cadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\n#&gt; Lincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\n#&gt; Chrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\n#&gt; Fiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\n#&gt; Honda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\n#&gt; Toyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\n#&gt; Toyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\n#&gt; Dodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\n#&gt; AMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\n#&gt; Camaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\n#&gt; Pontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\n#&gt; Fiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\n#&gt; Porsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\n#&gt; Lotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\n#&gt; Ford Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\n#&gt; Ferrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\n#&gt; Maserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\n#&gt; Volvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n#&gt; \n#&gt; [[2]]\n#&gt; [1] 0 0 0 0\n#&gt; \n#&gt; [[3]]\n#&gt;      [,1] [,2] [,3]\n#&gt; [1,]    1    0    0\n#&gt; [2,]    0    1    0\n#&gt; [3,]    0    0    1"
  },
  {
    "objectID": "lectures/1b.html#comparing-numbers-1",
    "href": "lectures/1b.html#comparing-numbers-1",
    "title": "Computational Setup",
    "section": "Comparing Numbers",
    "text": "Comparing Numbers\nYou can compare two numbers, or objects, that will result in a logical output."
  },
  {
    "objectID": "lectures/1b.html#comparing-numbers-operators",
    "href": "lectures/1b.html#comparing-numbers-operators",
    "title": "Computational Setup",
    "section": "Comparing Numbers Operators",
    "text": "Comparing Numbers Operators\n\n\n\nOperator\nDescription\n\n\n\n\n&gt;\nGreater Than\n\n\n&lt;\nLess Than\n\n\n&gt;=\nGreater than or equal\n\n\n&lt;=\nLess than or equal\n\n\n==\nEquals\n\n\n!=\nNot Equals"
  },
  {
    "objectID": "lectures/1b.html#labeled-lists-key-value",
    "href": "lectures/1b.html#labeled-lists-key-value",
    "title": "Computational Setup",
    "section": "Labeled Lists (Key-Value)",
    "text": "Labeled Lists (Key-Value)\n\n\nCode\nlist_two &lt;- list(data = mtcars, \n                 vector  = rep(0, 4),\n                 matricx = diag(rep(1, 3)))\nlist_two\n\n\n#&gt; $data\n#&gt;                      mpg cyl  disp  hp drat    wt  qsec vs am gear carb\n#&gt; Mazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\n#&gt; Mazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\n#&gt; Datsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\n#&gt; Hornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\n#&gt; Hornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\n#&gt; Valiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\n#&gt; Duster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\n#&gt; Merc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\n#&gt; Merc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\n#&gt; Merc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\n#&gt; Merc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\n#&gt; Merc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\n#&gt; Merc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\n#&gt; Merc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\n#&gt; Cadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\n#&gt; Lincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\n#&gt; Chrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\n#&gt; Fiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\n#&gt; Honda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\n#&gt; Toyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\n#&gt; Toyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\n#&gt; Dodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\n#&gt; AMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\n#&gt; Camaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\n#&gt; Pontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\n#&gt; Fiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\n#&gt; Porsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\n#&gt; Lotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\n#&gt; Ford Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\n#&gt; Ferrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\n#&gt; Maserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\n#&gt; Volvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n#&gt; \n#&gt; $vector\n#&gt; [1] 0 0 0 0\n#&gt; \n#&gt; $matricx\n#&gt;      [,1] [,2] [,3]\n#&gt; [1,]    1    0    0\n#&gt; [2,]    0    1    0\n#&gt; [3,]    0    0    1\n\n\nCode\nlist_two$vector\n\n\n#&gt; [1] 0 0 0 0"
  },
  {
    "objectID": "lectures/1b.html#resources-in-programming",
    "href": "lectures/1b.html#resources-in-programming",
    "title": "Computational Setup",
    "section": "Resources in Programming",
    "text": "Resources in Programming\nR Basics Material"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to Machine Learning!",
    "section": "",
    "text": "NoteBrief Introduction\n\n\n\n\n\nWelcome to the course! This is the home page of the course where I will provide a recap on what was covered in the week. Here I will post any documents or videos for your reference. If you have any questions, please email me at isaac.qs@csuci.edu.\n\n\n\n\n\n\n\n\n\nNoteQuarto Template for HW\n\n\n\n\n\nquarto use template inqs909/qs_hw\n\n\n\n\n\n\n\n\n\nNoteDiscord Server\n\n\n\n\n\nWill post if class creates one.\n\n\n\n\n\n\n\n\n\nNoteIntroduction to Statistics Book\n\n\n\n\n\nhttps://openintro-ims.netlify.app/\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 3\n\n\nThis week looks at R basics in terms of functions and tensors.\n\n\n\n\n\nFeb 10, 2026\n\n\n\n\n\n\n\nWeek 2\n\n\nThis week looks at R basics in terms of functions and tensors.\n\n\n\n\n\nFeb 2, 2026\n\n\n\n\n\n\n\nWeek 1\n\n\nThis week is designed to be an introduction week. We will briefly discuss topics related to the course. Then we will look at installing R, Positron, Torch, and Stan.\n\n\n\n\n\nJan 26, 2026\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "exc/exc_2.html",
    "href": "exc/exc_2.html",
    "title": "Extra Credit 2",
    "section": "",
    "text": "After reading one book below, create a video essay that summarizes the book, provide a brief analysis in supporting or opposing the book, and connect key elements of the book to your every day life. The video essay should be 10 minutes being narrated by your own voice. Use visual aids, such as a powerpoint presentation, to highlight your main findings, and how it relates to your own life. All books should be available through the Broome Library.\nBooks:\n\nMake it Stick: The Science of Successful Learning\n\nPeter Brown\n\nTeach Yourself How to Learn: Strategies you can use to ace any course\n\nSaundra McGuire\n\nLimitless Mind\n\nJo Boaler\n\nHappiness: A Guide to Developing Life’s\n\nMatthieu Ricard\n\nGrit: The Power of Passion and Perserverance\n\nAngela Duckworth\n\nMindset: The New Psychology of Success\n\nCarol Dweck\n\n\nVideo Essay Guidelines:\n\n10 Minutes Long\nUse of visual aids\nNarrated by your own voice\nDue 5/15/2026\n\nWorth 2 final grade percentage points."
  },
  {
    "objectID": "exc.html",
    "href": "exc.html",
    "title": "Extra Credit",
    "section": "",
    "text": "Extra Credit is designed to expand on different topics that related to Machine Learning, but are not necessarily required for the course. Additionally, these opportunities provide students relief when unexpected situations occur during the semester. While it is not required, I encourage everyone to attempt each opportunity.\nBelow is more information on each assignment.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExtra Credit 1\n\n\nInstructions for extra credit one.\n\n\n\n\n\nJan 15, 2026\n\n\n\n\n\n\n\n\n\n\n\n\nExtra Credit 2\n\n\nInstructions for extra credit two.\n\n\n\n\n\nJan 15, 2026\n\n\n\n\n\n\n\n\n\n\n\n\nExtra Credit 3\n\n\nInstructions for extra credit three.\n\n\n\n\n\nJan 15, 2026\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "books.html",
    "href": "books.html",
    "title": "Books",
    "section": "",
    "text": "A list of recommended books to learn more about Statistics, the majority are freely available from the Broome Library:"
  },
  {
    "objectID": "books.html#basics",
    "href": "books.html#basics",
    "title": "Books",
    "section": "Basics",
    "text": "Basics\n\nIntroduction to Statistics and Data Analysis\n\nHeumann and Shalabh\n\nStatistical Foundations, Reasoning and Inference\n\nKauermann, Küchenhoff, and Heumann"
  },
  {
    "objectID": "books.html#regression",
    "href": "books.html#regression",
    "title": "Books",
    "section": "Regression",
    "text": "Regression\n\nGeneralized Linear Models With Examples in R\n\nDunn and Smyth\nGraduate\n\nLinear and Generalized Linear Mixed Models and Their Applications (2nd Edition)\n\nJiang and Nguyen\nGraudate\n\nRegression Modeling Strategies\n\nHarrell\nUndergraduate\n\nVector Generalized Linear and Additive Models\n\nYee\nGraduate"
  },
  {
    "objectID": "books.html#nonparametric",
    "href": "books.html#nonparametric",
    "title": "Books",
    "section": "Nonparametric",
    "text": "Nonparametric\n\nSemiparametric Regression with R\n\nHarezlak, Ruppert, and Wand\nGraduate"
  },
  {
    "objectID": "books.html#computational",
    "href": "books.html#computational",
    "title": "Books",
    "section": "Computational",
    "text": "Computational\n\nBootstrap Methods with applications in R\n\nDikta and Scheer\nGraduate\n\nModern Optimization with R (2nd Edition)\n\nCortez\nGraduate\n\nComputational Statistics\n\nGentle\n\nMonte Carlo and Quasi-Monte Carlo Sampling\n\nLemieux\n\nStatistics With Julia\n\nNazarathy andKlok\n\nIntroducing Monte Carlo Methods in R\n\nRobert and Casella\n\nPermutation Statistical Methods with R\n\nBerry, Kvamme, Johnston, and Mielke\n\nMonte Carlo Strategies in Scientific Computing\n\nLiu"
  },
  {
    "objectID": "books.html#bayesian",
    "href": "books.html#bayesian",
    "title": "Books",
    "section": "Bayesian",
    "text": "Bayesian\n\nIntroduction to Bayesian Inference, Methods and Computation\n\nHeard\n\nApplied Bayesian Statistics\n\nCowles\n\nBayesian Statistical Modeling with Stan, R, and Python\n\nMatsuura\n\nBayesian Essentials in R\n\nMarin and Robert"
  },
  {
    "objectID": "books.html#theoretical",
    "href": "books.html#theoretical",
    "title": "Books",
    "section": "Theoretical",
    "text": "Theoretical\n\nEssentials of Stochastic Processes (3rd Edition)\n\nDurrett\nGraduate\n\nA Concise Introduction to Measure Theory\n\nShirali\nGraduate\n\nLarge Sample Techniques for Statistics (2nd Edition)\n\nJiang\nGraduate\n\nA Course in Mathematical Statistics and Large Sample Theory\n\nBhattacharya, Lin, and Patrangenaru\nGraduate\n\nMixture and Hidden Markov Models with R\n\nVisser and Speekenbrink\nUndergraduate\n\nModern Mathematical Statistics (3rd Edition)\n\nDevore, Berk, and Carlton\nUndergraduate\n\nProbability Theory (3rd Edition)\n\nKlenke\nGraduate\n\nTesting Statistical Hypotheses (4th Edition)\n\nLehmann and Romano\nGraduate\n\nTheory of Point Estimation\n\nLehmann and Casella\nGraduate\nMay not be available"
  },
  {
    "objectID": "books.html#longitudinal-data-analysis",
    "href": "books.html#longitudinal-data-analysis",
    "title": "Books",
    "section": "Longitudinal Data Analysis",
    "text": "Longitudinal Data Analysis\n\nLongitudinal Categorical Data Analysis\n\nSutradhar"
  },
  {
    "objectID": "books.html#survival-analysis",
    "href": "books.html#survival-analysis",
    "title": "Books",
    "section": "Survival Analysis",
    "text": "Survival Analysis\n\nStatistical Modelling of Survival Data with Random Effects\n\nHa, Jeong, and Lee\n\nSurvival Analysis (3rd Edition)\n\nKleinbaum and Klein\n\nApplied Survival Analysis in R\n\nMoore\n\nBayesian Survival Analysis\n\nIbrahim, Chen, and Sinha\n\nSurvival Analysis Techniques for Censored and Truncated Data (2nd Edition)\n\nKlein and Moeschberger"
  },
  {
    "objectID": "books.html#machine-learning",
    "href": "books.html#machine-learning",
    "title": "Books",
    "section": "Machine Learning",
    "text": "Machine Learning\n\nFundamental of High-Dimensional Statistics\n\nLederer\n\nAn Introduction to Statistical Learning (2nd Edition)\n\nJames, Witten, Hastie and Tibshirani\n\nStatistical Learning from a Regression Perspective (2nd Edition)\n\nBerk\n\nElements of Statistical Learning\n\nHastie, Friedman, and Tibshirani\n\nStatistics for High Dimensional Data\n\nBühlmann and van der Geer\n\nProbability and Statistics for Machine Learning\n\nDas Gupta"
  },
  {
    "objectID": "books.html#time-series",
    "href": "books.html#time-series",
    "title": "Books",
    "section": "Time-Series",
    "text": "Time-Series\n\nIntroduction to Time Series and Forcasting (3rd Edition)\n\nBrockwell and Davis\n\nTime Series Analysis and Its Applications\n\nShumway and Stoffer\n\nTime Series Analysis for the State-Space Model with R/Stan\n\nHagiwara"
  },
  {
    "objectID": "books.html#study-desing-and-causal-inference",
    "href": "books.html#study-desing-and-causal-inference",
    "title": "Books",
    "section": "Study Desing and Causal Inference",
    "text": "Study Desing and Causal Inference\n\nCausal Inference What IF\n\nHernán and Robins\n\nDesign of Observational Studies\n\nRosenbaum\n\n\nBolded Titles, I have read thoroughly."
  },
  {
    "objectID": "exc/exc_1.html",
    "href": "exc/exc_1.html",
    "title": "Extra Credit 1",
    "section": "",
    "text": "Write a 2-page report practices related to self care. As you move on through college and your future careers, it is important to practice self care. For this extra credit assignments, write about what are some practices you will do to for your well being.\nWorth 1 percent points.\nReport guidelines\n\n2 Pages\nDouble Spaced\n12 point font\nDue 02/15/2026"
  },
  {
    "objectID": "exc/exc_3.html",
    "href": "exc/exc_3.html",
    "title": "Extra Credit 3",
    "section": "",
    "text": "After reading one book below, create a video essay that summarizes the book, provide a brief analysis in supporting or opposing the book, and connect key elements of the book to your every day life. The video essay should be 10 minutes being narrated by your own voice. Use is visual aids, such as a powerpoint presentation, to highlight your main findings. All books should be available through the Broome Library.\nMATH 453 STUDENTS: You must choose a different book from Math 453 in order to receive credit.\nBooks:\n\nEmpire of AI\n\nKaren Hao\n\nThe Last Human Job\n\nAllison Pugh\n\nThe Book of Why\n\nJudea Pearl\n\nAlgorithms of Oppression\n\nSafiya Umoja Noble\n\nData Feminism\n\nCatherine D’Ignazio and Lauren Klein\n\nWeapons of Math Destruction\n\nCathy O’Niel\n\nInvisible Women: Data bias in a world designed for men\n\nCaroline Criado Perez\n\nFactfulness: Ten Reasons We’re Wrong About the World… and Why Things are Better Than You Think\n\nHans Rosling\n\nArtificial Unintelligence: How Computers Misunderstand the World\n\nMerideth Broussard\n\nTechnically Wrong: Sexist Apps, Biased Algorithms, and Other Threats of Toxic Tech\n\nSara Wachter-Boettcher\n\nUnmasking AI\n\nJoy Buolamwini\n\nRace After Technology\n\nRuha Benjamin\n\nCloud Ethics\n\nLouise Amoore\n\nMore than a Glitch\n\nMeridith Broussard\n\nDigitizing Race\n\nLisa Nakamura\n\nData Action\n\nSarah Williams\n\nOR ANY Book Approved By Me (Deadline for Approval by March 29, 2026)\n\nVideo Essay Guidelines:\n\n10 Minutes Long\nUse of visual aids\nNarrated by your own voice\nDue 5/15/2026\n\nWorth 2 final grade percentage points."
  },
  {
    "objectID": "lectures/1a.html#introductions-1",
    "href": "lectures/1a.html#introductions-1",
    "title": "Math 408",
    "section": "Introductions",
    "text": "Introductions\n\nSan Bernardino, CA\nCSU Monterey Bay\n\nBS Biology\n\nSan Diego State University\n\nMaster’s in Public Health\n\nUC Riverside\n\nPhD in Applied Statistics"
  },
  {
    "objectID": "lectures/1a.html#introductions-2",
    "href": "lectures/1a.html#introductions-2",
    "title": "Math 408",
    "section": "Introductions",
    "text": "Introductions\n\nName\nYear\nMajor\nFun Fact\nCareer Goal"
  },
  {
    "objectID": "lectures/1a.html#class-setup-1",
    "href": "lectures/1a.html#class-setup-1",
    "title": "Math 408",
    "section": "Class Setup",
    "text": "Class Setup\n\nHomework Assignments\nFinal Presentation\nFinal Write Up\nExtra Credit"
  },
  {
    "objectID": "lectures/1a.html#syllabus",
    "href": "lectures/1a.html#syllabus",
    "title": "Math 408",
    "section": "Syllabus",
    "text": "Syllabus\nm408.inqs.info/syllabus"
  },
  {
    "objectID": "lectures/1a.html#tools",
    "href": "lectures/1a.html#tools",
    "title": "Math 408",
    "section": "Tools",
    "text": "Tools\n\nR\nTorch\nStan\nQuarto"
  },
  {
    "objectID": "lectures/1a.html#ide",
    "href": "lectures/1a.html#ide",
    "title": "Math 408",
    "section": "IDE",
    "text": "IDE\n\nPositron\nVS Code\nVS Codium\nRStudio"
  },
  {
    "objectID": "lectures/1a.html#the-final-project",
    "href": "lectures/1a.html#the-final-project",
    "title": "Math 408",
    "section": "The Final Project",
    "text": "The Final Project\nThe final project is designed for you to demonstrate your understanding of neural networks."
  },
  {
    "objectID": "lectures/1a.html#you-may",
    "href": "lectures/1a.html#you-may",
    "title": "Math 408",
    "section": "You may …",
    "text": "You may …\nBuild a neural network related to any data you are interested in to predict an outcome."
  },
  {
    "objectID": "lectures/1a.html#you-may-1",
    "href": "lectures/1a.html#you-may-1",
    "title": "Math 408",
    "section": "You may …",
    "text": "You may …\nUse existing neural networks for classification, transcription or any other purpose."
  },
  {
    "objectID": "lectures/1a.html#you-may-2",
    "href": "lectures/1a.html#you-may-2",
    "title": "Math 408",
    "section": "You may …",
    "text": "You may …\nExplore advance topics related to neural networks, such as\n\nPhysics-informend Neural Networks\nGraph Neural Networks"
  },
  {
    "objectID": "lectures/1a.html#for-each-project",
    "href": "lectures/1a.html#for-each-project",
    "title": "Math 408",
    "section": "For each project",
    "text": "For each project\nYou will need to describe\n\nThe model used\nType of input data\nOutput of interest\nA working example\nModel Diagnostics"
  },
  {
    "objectID": "lectures/1a.html#final-presentation-and-report",
    "href": "lectures/1a.html#final-presentation-and-report",
    "title": "Math 408",
    "section": "Final Presentation and Report",
    "text": "Final Presentation and Report\nYou will demonstrate your results in a 10 minute during Week 15 or Finals Week.\nYou written report will be due by the end of final’s week.\nMore information will be provided on a later date."
  },
  {
    "objectID": "lectures/1a.html#use-of-generative-ai-policy",
    "href": "lectures/1a.html#use-of-generative-ai-policy",
    "title": "Math 408",
    "section": "Use of Generative AI Policy",
    "text": "Use of Generative AI Policy\nThe use of generative artificial intelligence (AI) to complete any part or all of an assignment/exam is strictly prohibited in this class. This includes, but not limited to, ChatGPT, Claude, Meta AI, and Google Gemini.\n\nYou may use AI to enhance you understanding of the material.\n\n\nYou may not use AI to complete assignments.\n\n\nYou may not upload any course material to any AI platforms such as ChatGPT, Claude, Meta AI, and Google Gemini. Exceptions are allowed for DASS-approved services."
  },
  {
    "objectID": "lectures/1a.html#use-of-ai",
    "href": "lectures/1a.html#use-of-ai",
    "title": "Math 408",
    "section": "Use of AI",
    "text": "Use of AI\nThere are consequences when you use of AI:\n\nEducational Mislearning\nTrusting AI\nStolen Work\nPrivacy Concerns\nEnvironmental Impacts\nWorking Exploitation"
  },
  {
    "objectID": "lectures/1a.html#educational-mislearning",
    "href": "lectures/1a.html#educational-mislearning",
    "title": "Math 408",
    "section": "Educational Mislearning",
    "text": "Educational Mislearning\nThe purpose of this class, and college, is for you to learn about critical thinking skills and perseverance. Using AI will only teach you how to get an answer, which may or may not be correct.\n\nYou will not develop the skills needed to problem solve a challenge. Additionally, developing grit is essential to become successful in college and life. There is no easy way out and AI is an illusion to your success in life.\n\n\nTo learn something, it requires hours of work! If not years!"
  },
  {
    "objectID": "lectures/1a.html#trusting-ai",
    "href": "lectures/1a.html#trusting-ai",
    "title": "Math 408",
    "section": "Trusting AI",
    "text": "Trusting AI\nWhen using AI, you must acknowledge its limitations:\n\nResponses provided may be incorrect\nResponses may not be fair\nCompanies may manipulate responses and/or terms of service for their benefit\nCompanies may not have your best interst in mind\n\n\nYou should always proceed with caution utilizing these tools!"
  },
  {
    "objectID": "lectures/1a.html#stolen-work",
    "href": "lectures/1a.html#stolen-work",
    "title": "Math 408",
    "section": "Stolen Work",
    "text": "Stolen Work\n\nAdditionally, all these individuals are not receiving any royalties for the work to be used in creating generative AI models.\n\n\nInside Higher Ed and The New Yorker highlight individual’s concern of their work being used to train AI models."
  },
  {
    "objectID": "lectures/1a.html#privacy-concerns",
    "href": "lectures/1a.html#privacy-concerns",
    "title": "Math 408",
    "section": "Privacy Concerns",
    "text": "Privacy Concerns\nThe use of generative AI raises concerns of what data is being harvested from us, possibly without informed consent or knowledge of impacts.\n\nWhen you use any large language models, you do not know what information is being harvested from you.\n\n\nDo you want to upload your thoughts and ideas to a company that can monetize, and possibly exploit you.\n\n\nDoes your Professors consent with you uploading their assignments to large language models?\n\n\nStanford provided a report highlighting the risks of our personal data use in large language models."
  },
  {
    "objectID": "lectures/1a.html#environmental-impact",
    "href": "lectures/1a.html#environmental-impact",
    "title": "Math 408",
    "section": "Environmental Impact",
    "text": "Environmental Impact\nIn order to run these large language models, companies need to use a large amounts of energy. This is because large servers are needed to both train and execute a model.\n\nThe LA Times reports the potential impact that running AI models in California.\n\n\nAdditionally, Time reports that a ChatGPT query uses ten times more energy than a Google search query, and global AI demands can consume of 1 trillion gallons of water by 2027.\n\n\nThere are also environmental justice questions about where these data centers are constructed."
  },
  {
    "objectID": "lectures/1a.html#worker-exploitation",
    "href": "lectures/1a.html#worker-exploitation",
    "title": "Math 408",
    "section": "Worker Exploitation",
    "text": "Worker Exploitation\nThe Washington Post and Time (Article 1 and Article 2) reported that AI companies utilize “digital sweatshops” to classify data points for model training.\n\nThere is a human cost from the Global South, both financially and mentally, to develop the AI models for users in the United States and Europe.\n\n\nWe must be conscious consumers and demand more from these companies to provide safe working conditions and livable wages."
  },
  {
    "objectID": "lectures/1a.html#is-using-ai-bad",
    "href": "lectures/1a.html#is-using-ai-bad",
    "title": "Math 408",
    "section": "Is Using AI Bad?",
    "text": "Is Using AI Bad?\n\nYes/No/I don’t know"
  },
  {
    "objectID": "lectures/1a.html#privacy-concerns-links",
    "href": "lectures/1a.html#privacy-concerns-links",
    "title": "Math 408",
    "section": "Privacy Concerns Links",
    "text": "Privacy Concerns Links\n\nOpenAI Says It’s Scanning Users’ ChatGPT Conversations and Reporting Content to the Police\nPrivacy in an AI Era: How Do We Protect Our Personal Information?"
  },
  {
    "objectID": "lectures/1a.html#labor-violations-links",
    "href": "lectures/1a.html#labor-violations-links",
    "title": "Math 408",
    "section": "Labor Violations Links",
    "text": "Labor Violations Links\n\nThe Emotional Labor Behind AI Intimacy\nHow thousands of ‘overworked, underpaid’ humans train Google’s AI to seem smart"
  },
  {
    "objectID": "lectures/1a.html#affecting-communities-links",
    "href": "lectures/1a.html#affecting-communities-links",
    "title": "Math 408",
    "section": "Affecting Communities Links",
    "text": "Affecting Communities Links\n\nAI surveillance and data colonialism shape African conflicts\nAfrican workers are taking on Meta and the world should pay attention\n‘It’s destroyed me completely’: Kenyan moderators decry toll of training of AI models\nThe AI Industry Is Traumatizing Desperate Contractors in the Developing World for Pennies\nChatGPT advises women to ask for lower salaries, study finds\nThe Impact of the Use of AI on People with Disabilities"
  },
  {
    "objectID": "lectures/1a.html#ideas-and-learning-links",
    "href": "lectures/1a.html#ideas-and-learning-links",
    "title": "Math 408",
    "section": "Ideas and Learning Links",
    "text": "Ideas and Learning Links\n\nStudent’s Right to Refuse AI\nAI is homogenizing your thoughts\nThe Incuriosity Engine\nNew Junior Developers Can’t Actually Code"
  },
  {
    "objectID": "lectures/1a.html#environmental-costs",
    "href": "lectures/1a.html#environmental-costs",
    "title": "Math 408",
    "section": "Environmental Costs",
    "text": "Environmental Costs\n\n‘I can’t drink the water’ - life next to a US data centre"
  },
  {
    "objectID": "lectures/1a.html#extra-credits-1",
    "href": "lectures/1a.html#extra-credits-1",
    "title": "Math 408",
    "section": "Extra Credits",
    "text": "Extra Credits\n\nExtra Credit 1\nExtra Credit 2\nExtra Credit 3"
  },
  {
    "objectID": "lectures/2a.html#r-packages",
    "href": "lectures/2a.html#r-packages",
    "title": "R Basics",
    "section": "R Packages",
    "text": "R Packages\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "lectures/2a.html#class-setup-modifications",
    "href": "lectures/2a.html#class-setup-modifications",
    "title": "R Basics",
    "section": "Class Setup Modifications",
    "text": "Class Setup Modifications\n\nTuesday\n\nLecture on Neural Networks\n\nThursday\n\nWork on Project\nWork on Goals that leads to the completion of your project.\n\n\n\nThis will begin next week."
  },
  {
    "objectID": "lectures/2a.html#why-the-change",
    "href": "lectures/2a.html#why-the-change",
    "title": "R Basics",
    "section": "Why the change",
    "text": "Why the change\nThis will help ensure projects get done, and students to learn at their own pace."
  },
  {
    "objectID": "lectures/2a.html#goals",
    "href": "lectures/2a.html#goals",
    "title": "R Basics",
    "section": "Goals",
    "text": "Goals\nEvery week, your homework is to create one SMART Goal and provide evidence that you reached that goal.\n\nIf you were not able to reach your goal, provide clear steps on how to achieve it the following week."
  },
  {
    "objectID": "lectures/2a.html#smart-goals",
    "href": "lectures/2a.html#smart-goals",
    "title": "R Basics",
    "section": "SMART Goals",
    "text": "SMART Goals\nSMART goals are a structured way to set clear, achievable objectives.\nThey help turn vague intentions into concrete plans."
  },
  {
    "objectID": "lectures/2a.html#what-does-smart-stand-for",
    "href": "lectures/2a.html#what-does-smart-stand-for",
    "title": "R Basics",
    "section": "What Does SMART Stand For?",
    "text": "What Does SMART Stand For?\n\nSpecific: Be clear and focused.\nMeasurable: A criteria to track progress.\nAchievable: Be realistic and attainable.\nRelevant: Make it align with your priorities.\nTime-bound: Have a clear deadline."
  },
  {
    "objectID": "lectures/2a.html#example-not-smart",
    "href": "lectures/2a.html#example-not-smart",
    "title": "R Basics",
    "section": "Example (Not SMART)",
    "text": "Example (Not SMART)\n\nI want to get better at R programming."
  },
  {
    "objectID": "lectures/2a.html#example-smart",
    "href": "lectures/2a.html#example-smart",
    "title": "R Basics",
    "section": "Example (SMART)",
    "text": "Example (SMART)\n\nI will learn how to use for loops in R by writing at least one loop-based script in a week that performs tasks such as iterating over vectors and data frames."
  },
  {
    "objectID": "lectures/2a.html#why-use-smart-goals",
    "href": "lectures/2a.html#why-use-smart-goals",
    "title": "R Basics",
    "section": "Why Use SMART Goals?",
    "text": "Why Use SMART Goals?\n\nImproves focus and motivation\nMakes progress measurable\nIncreases likelihood of success\nReduces ambiguity"
  },
  {
    "objectID": "lectures/2a.html#homework-0",
    "href": "lectures/2a.html#homework-0",
    "title": "R Basics",
    "section": "Homework 0",
    "text": "Homework 0\nProvide some background information about your experience in computing. Have you coded any algorithms? Have you’ve done any statistical analysis? What programming languages have used before?\nWrite a paragraph of what you want to achieve in this machine learning course, and create one smart goal to achieve by next Thursday.\nProvide a description of what you want to do for your project."
  },
  {
    "objectID": "lectures/2a.html#workspaces-1",
    "href": "lectures/2a.html#workspaces-1",
    "title": "R Basics",
    "section": "Workspaces",
    "text": "Workspaces\nWorkspaces allows you to create locations on your computer and set up a computing environment in one location."
  },
  {
    "objectID": "lectures/2a.html#r-as-a-calculator",
    "href": "lectures/2a.html#r-as-a-calculator",
    "title": "R Basics",
    "section": "R as a calculator",
    "text": "R as a calculator\nR can evaluate different expressions in the console tab.\nTry the following:\n\n\\(4(4+2)/34\\)\n\\(6^3\\)\n\\(3-1\\)\n\\(4+4/3+45(32*34-54)\\)"
  },
  {
    "objectID": "lectures/2a.html#r-functions",
    "href": "lectures/2a.html#r-functions",
    "title": "R Basics",
    "section": "R Functions",
    "text": "R Functions\nR functions performs tasks to specific data values.\nEvaluate the following values in R:\n\n\\(\\sqrt{3}\\)\n\\(e^3\\)\n\\(\\ln(53)\\)\n\\(\\log(324)\\)\n\\(\\sin(3)\\)\n\\(\\sin(3\\pi)\\)"
  },
  {
    "objectID": "lectures/2a.html#types-of-data",
    "href": "lectures/2a.html#types-of-data",
    "title": "R Basics",
    "section": "Types of Data",
    "text": "Types of Data\n\nNumeric\nCharacter\nLogical\nMissing\n\nEvaluate the following code:\nis.numeric(1)\nis.numeric(\"1\")\nis.numeric(T)\nis.numeric(NA)"
  },
  {
    "objectID": "lectures/2a.html#types-of-objects",
    "href": "lectures/2a.html#types-of-objects",
    "title": "R Basics",
    "section": "Types of Objects",
    "text": "Types of Objects\nIn R, an object contains a set of data. The most common types are vectors and matrix.\nRun this code and print out the objects in the console:\nx &lt;- 3:34\ny &lt;- matrix(1:20, nrow = 4)"
  },
  {
    "objectID": "lectures/2a.html#data-frames",
    "href": "lectures/2a.html#data-frames",
    "title": "R Basics",
    "section": "Data Frames",
    "text": "Data Frames\nData frames can be thought of as R’s version of a data set.\nPlay around with mtcars:\n\nmtcars \n\n#&gt;                      mpg cyl  disp  hp drat    wt  qsec vs am gear carb\n#&gt; Mazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\n#&gt; Mazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\n#&gt; Datsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\n#&gt; Hornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\n#&gt; Hornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\n#&gt; Valiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\n#&gt; Duster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\n#&gt; Merc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\n#&gt; Merc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\n#&gt; Merc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\n#&gt; Merc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\n#&gt; Merc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\n#&gt; Merc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\n#&gt; Merc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\n#&gt; Cadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\n#&gt; Lincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\n#&gt; Chrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\n#&gt; Fiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\n#&gt; Honda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\n#&gt; Toyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\n#&gt; Toyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\n#&gt; Dodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\n#&gt; AMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\n#&gt; Camaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\n#&gt; Pontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\n#&gt; Fiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\n#&gt; Porsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\n#&gt; Lotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\n#&gt; Ford Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\n#&gt; Ferrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\n#&gt; Maserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\n#&gt; Volvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2"
  },
  {
    "objectID": "lectures/2a.html#lists",
    "href": "lectures/2a.html#lists",
    "title": "R Basics",
    "section": "Lists",
    "text": "Lists\nList can be thought as an extended vector, but each element is a different R object.\nTry playing with this R object:\n\nlist_one &lt;- list(mtcars, rep(0, 4),\n                 diag(rep(1, 3)))\nlist_one\n\n#&gt; [[1]]\n#&gt;                      mpg cyl  disp  hp drat    wt  qsec vs am gear carb\n#&gt; Mazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\n#&gt; Mazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\n#&gt; Datsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\n#&gt; Hornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\n#&gt; Hornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\n#&gt; Valiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\n#&gt; Duster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\n#&gt; Merc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\n#&gt; Merc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\n#&gt; Merc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\n#&gt; Merc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\n#&gt; Merc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\n#&gt; Merc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\n#&gt; Merc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\n#&gt; Cadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\n#&gt; Lincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\n#&gt; Chrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\n#&gt; Fiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\n#&gt; Honda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\n#&gt; Toyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\n#&gt; Toyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\n#&gt; Dodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\n#&gt; AMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\n#&gt; Camaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\n#&gt; Pontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\n#&gt; Fiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\n#&gt; Porsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\n#&gt; Lotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\n#&gt; Ford Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\n#&gt; Ferrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\n#&gt; Maserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\n#&gt; Volvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n#&gt; \n#&gt; [[2]]\n#&gt; [1] 0 0 0 0\n#&gt; \n#&gt; [[3]]\n#&gt;      [,1] [,2] [,3]\n#&gt; [1,]    1    0    0\n#&gt; [2,]    0    1    0\n#&gt; [3,]    0    0    1"
  },
  {
    "objectID": "lectures/2a.html#comparing-numbers-1",
    "href": "lectures/2a.html#comparing-numbers-1",
    "title": "R Basics",
    "section": "Comparing Numbers",
    "text": "Comparing Numbers\nYou can compare two numbers, or objects, that will result in a logical output."
  },
  {
    "objectID": "lectures/2a.html#comparing-numbers-operators",
    "href": "lectures/2a.html#comparing-numbers-operators",
    "title": "R Basics",
    "section": "Comparing Numbers Operators",
    "text": "Comparing Numbers Operators\n\n\n\nOperator\nDescription\n\n\n\n\n&gt;\nGreater Than\n\n\n&lt;\nLess Than\n\n\n&gt;=\nGreater than or equal\n\n\n&lt;=\nLess than or equal\n\n\n==\nEquals\n\n\n!=\nNot Equals"
  },
  {
    "objectID": "lectures/2a.html#labeled-lists-key-value",
    "href": "lectures/2a.html#labeled-lists-key-value",
    "title": "R Basics",
    "section": "Labeled Lists (Key-Value)",
    "text": "Labeled Lists (Key-Value)\n\nlist_two &lt;- list(data = mtcars, \n                 vector  = rep(0, 4),\n                 matricx = diag(rep(1, 3)))\nlist_two\n\n#&gt; $data\n#&gt;                      mpg cyl  disp  hp drat    wt  qsec vs am gear carb\n#&gt; Mazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4\n#&gt; Mazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4\n#&gt; Datsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1\n#&gt; Hornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1\n#&gt; Hornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2\n#&gt; Valiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1\n#&gt; Duster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4\n#&gt; Merc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2\n#&gt; Merc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2\n#&gt; Merc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4\n#&gt; Merc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4\n#&gt; Merc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3\n#&gt; Merc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3\n#&gt; Merc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3\n#&gt; Cadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4\n#&gt; Lincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4\n#&gt; Chrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4\n#&gt; Fiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1\n#&gt; Honda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2\n#&gt; Toyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1\n#&gt; Toyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1\n#&gt; Dodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2\n#&gt; AMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2\n#&gt; Camaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4\n#&gt; Pontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2\n#&gt; Fiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1\n#&gt; Porsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2\n#&gt; Lotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2\n#&gt; Ford Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4\n#&gt; Ferrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6\n#&gt; Maserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8\n#&gt; Volvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2\n#&gt; \n#&gt; $vector\n#&gt; [1] 0 0 0 0\n#&gt; \n#&gt; $matricx\n#&gt;      [,1] [,2] [,3]\n#&gt; [1,]    1    0    0\n#&gt; [2,]    0    1    0\n#&gt; [3,]    0    0    1\n\nlist_two$vector\n\n#&gt; [1] 0 0 0 0"
  },
  {
    "objectID": "lectures/2a.html#resources-in-programming",
    "href": "lectures/2a.html#resources-in-programming",
    "title": "R Basics",
    "section": "Resources in Programming",
    "text": "Resources in Programming\nR Basics Material"
  },
  {
    "objectID": "lectures/2a.html#indexing-1",
    "href": "lectures/2a.html#indexing-1",
    "title": "R Basics",
    "section": "Indexing",
    "text": "Indexing\nWithin an R object, you can access an element by indexing it.\nIndexing tells R which values to output."
  },
  {
    "objectID": "lectures/2a.html#vectors",
    "href": "lectures/2a.html#vectors",
    "title": "R Basics",
    "section": "Vectors",
    "text": "Vectors\nA vector can be indexed by adding [] after the object’s name and specifying the number of each element.\nletters\nletters[13]"
  },
  {
    "objectID": "lectures/2a.html#matrices",
    "href": "lectures/2a.html#matrices",
    "title": "R Basics",
    "section": "Matrices",
    "text": "Matrices\nA matrix can be indexed by adding [] after the object’s name and specifying the number of each element. Separate the values by commas for specific indexes.\nx &lt;- matrix(1:40, nrow = 4)"
  },
  {
    "objectID": "lectures/2a.html#data-frames-1",
    "href": "lectures/2a.html#data-frames-1",
    "title": "R Basics",
    "section": "Data Frames",
    "text": "Data Frames\nData frames can be indexed using the $ operator and [].\nmtcars[,\"mpg\"]"
  },
  {
    "objectID": "lectures/2a.html#lists-1",
    "href": "lectures/2a.html#lists-1",
    "title": "R Basics",
    "section": "Lists",
    "text": "Lists\nLists can be indexed using the [[]] for a specific element of a list.\ntoy_list &lt;- list(x = letters,\n                 y = mtcars,\n                 z = list(x = diag(rep(1, 5),\n                          y = matrix(1:40, nrow = 5),\n                          z = band_members)))"
  },
  {
    "objectID": "lectures/2a.html#ifelse-statements-1",
    "href": "lectures/2a.html#ifelse-statements-1",
    "title": "R Basics",
    "section": "if/else Statements",
    "text": "if/else Statements\nif/else statements are used to conduct specific tasks depending on the conditions"
  },
  {
    "objectID": "lectures/2a.html#if-statement",
    "href": "lectures/2a.html#if-statement",
    "title": "R Basics",
    "section": "if Statement",
    "text": "if Statement\nAn if statement is used to if you want R to perform a specific function if a certain condition is met. An if statement will only run a task if a logical is returned. You will need type if, followed by the condition (as a logical) in parentheses, then the task."
  },
  {
    "objectID": "lectures/2a.html#example",
    "href": "lectures/2a.html#example",
    "title": "R Basics",
    "section": "Example",
    "text": "Example\nx &lt;- sample(-10:10,1)\nif (x &gt; 0){\n  print(\"Positive\")\n}\nprint(x)"
  },
  {
    "objectID": "lectures/2a.html#else-statement",
    "href": "lectures/2a.html#else-statement",
    "title": "R Basics",
    "section": "else statement",
    "text": "else statement\nAn else statement will conduct a different task if the if statement does not conduct the tasks."
  },
  {
    "objectID": "lectures/2a.html#example-1",
    "href": "lectures/2a.html#example-1",
    "title": "R Basics",
    "section": "Example",
    "text": "Example\nx &lt;- sample(-10:10,1)\nif (x &gt; 0 ){\n  print(\"Positive\")\n} else {\n  print(\"Non-positive\")\n} \nprint(x)"
  },
  {
    "objectID": "lectures/2a.html#chain-ifelse-statement",
    "href": "lectures/2a.html#chain-ifelse-statement",
    "title": "R Basics",
    "section": "Chain if/else statement",
    "text": "Chain if/else statement\nIf you have more than two options, you can chain if/else statements by adding an if statement immediately after the word else."
  },
  {
    "objectID": "lectures/2a.html#example-2",
    "href": "lectures/2a.html#example-2",
    "title": "R Basics",
    "section": "Example",
    "text": "Example\nx &lt;- sample(-10:10,1)\nif (x &gt; 0 ){\n  print(\"Positive\")\n} else if (x == 0) {\n  print(\"Zero\")\n} else {\n  print(\"Negative\")\n}\nprint(x)"
  },
  {
    "objectID": "lectures/2a.html#built-in-functions-1",
    "href": "lectures/2a.html#built-in-functions-1",
    "title": "R Basics",
    "section": "Built-in Functions",
    "text": "Built-in Functions\nThere are several available functions in R to conduct specific statistical methods or tasks"
  },
  {
    "objectID": "lectures/2a.html#help-documentation",
    "href": "lectures/2a.html#help-documentation",
    "title": "R Basics",
    "section": "Help Documentation",
    "text": "Help Documentation\n\n\n\n\n\n\n\nSection\nDescription\n\n\n\n\nDescription\nProvides a brief introduction of the function\n\n\nUsage\nProvides potential usage of the function\n\n\nArguments\nArguments that the function can take\n\n\nDetails\nAn in depth description of the function\n\n\nValue\nProvides information of the output produced by the function\n\n\nNotes\nAny need to know information about the function\n\n\nAuthors\nDevelopers of the function\n\n\nReferences\nReferences to the model and function\n\n\nSee Also\nProvide information of supporting functions\n\n\nExamples\nExamples of the function"
  },
  {
    "objectID": "lectures/2a.html#generic-functions",
    "href": "lectures/2a.html#generic-functions",
    "title": "R Basics",
    "section": "Generic Functions",
    "text": "Generic Functions\nSeveral R objects have a known class attached to it. A specialized object designed to be read by generic functions, such as summary() and plot().\nFor example, the summary() is a generic for several types of functions: summary.aov(), summary.lm(), summary.glm(), and many more."
  },
  {
    "objectID": "lectures/2a.html#commonly-used-function",
    "href": "lectures/2a.html#commonly-used-function",
    "title": "R Basics",
    "section": "Commonly-used Function",
    "text": "Commonly-used Function\n\n\n\nFunctions\nDescription\n\n\n\n\naov()\nFits an ANOVA Model\n\n\nlm()\nFits a linear model\n\n\nglm()\nFits a general linear model\n\n\nt.test()\nConducts a t-test"
  },
  {
    "objectID": "lectures/2a.html#user-built-functions-1",
    "href": "lectures/2a.html#user-built-functions-1",
    "title": "R Basics",
    "section": "User-built functions",
    "text": "User-built functions\n\nFunctions created by the user for analysis\nNeeds to be ran once to the R environment\nWill be lost when R session is closed"
  },
  {
    "objectID": "lectures/2a.html#anatomy",
    "href": "lectures/2a.html#anatomy",
    "title": "R Basics",
    "section": "Anatomy",
    "text": "Anatomy\n\nname_of_function &lt;- function(data_1, data_2 = NULL, \n                             argument_1, argument_2 = TRUE, argument_3 = NULL,\n                             ...){\n  # Conduct Task\n  # Conduct Task\n  output_object &lt;- Tasks\n  return(output_object)\n}\n\n\n\nfunction: used to construct the function\ndata1: first data argument that needs to supplied\ndata2: second data argument that does not need to be supplied\nargument1: first argument must be supplied to alter function\nargument2: second argument to alter function, set to TRUE\nargument3: third argument that does not need to be supplied\n…: additional arguments supplied to other functions"
  },
  {
    "objectID": "lectures/2a.html#example-3",
    "href": "lectures/2a.html#example-3",
    "title": "R Basics",
    "section": "Example",
    "text": "Example\nCreate a function for\n\\[\ny = \\ln(x^2)\n\\]"
  },
  {
    "objectID": "lectures/2a.html#example-4",
    "href": "lectures/2a.html#example-4",
    "title": "R Basics",
    "section": "Example",
    "text": "Example\nCreate a function for\n\\[\nf(x) = \\left\\{\\begin{array}{cc}\nx^3 & x&lt;0\\\\\nx^2 + 5 & \\mathrm{otherwise}\n\\end{array} \\right.\n\\]"
  },
  {
    "objectID": "lectures/2a.html#example-5",
    "href": "lectures/2a.html#example-5",
    "title": "R Basics",
    "section": "Example",
    "text": "Example\nCreate a function for\n\\[\nf(x,y) = \\left\\{\\begin{array}{cc}\nx^3 e^y &  x&lt;0\\ \\\\\nx^2 + 5 + \\ln(y) & \\mathrm{otherwise}\n\\end{array} \\right.\n\\]"
  },
  {
    "objectID": "lectures/2a.html#example-6",
    "href": "lectures/2a.html#example-6",
    "title": "R Basics",
    "section": "Example",
    "text": "Example\nCreate the function that allows your to compute the z-score of a specific value x using the sampling distribution from a set of data (y vector):\n\\[\nz =  \\frac{x-\\bar y}{\\sqrt{s^2_{y}/n_y}}\n\\]"
  },
  {
    "objectID": "lectures/3a.html#r-packages",
    "href": "lectures/3a.html#r-packages",
    "title": "Neural Networks",
    "section": "R Packages",
    "text": "R Packages\n\n# install.packages(\"torch\")\n# install.packages(\"luz\")\n\nlibrary(torch)\nlibrary(luz) # high-level interface for torch\ntorch_manual_seed(13)"
  },
  {
    "objectID": "lectures/3a.html#data-in-python",
    "href": "lectures/3a.html#data-in-python",
    "title": "Neural Networks",
    "section": "Data in Python",
    "text": "Data in Python\nimport plotnine\nfrom plotnine.data import penguins\nclean_penguins = (\n    penguins\n        .dropna()\n        .drop(columns=[\"year\"])\n)"
  },
  {
    "objectID": "lectures/3a.html#what-is-machine-learning",
    "href": "lectures/3a.html#what-is-machine-learning",
    "title": "Neural Networks",
    "section": "What is Machine Learning?",
    "text": "What is Machine Learning?\nMachine Learning (ML) is the process of characterizing mathematical models, with the help of data, to predict outcomes of interest."
  },
  {
    "objectID": "lectures/3a.html#machine-learning-model",
    "href": "lectures/3a.html#machine-learning-model",
    "title": "Neural Networks",
    "section": "Machine Learning Model",
    "text": "Machine Learning Model\n\\[\nY = f(\\boldsymbol X; \\boldsymbol \\theta)\n\\]\n\n\\(Y\\): is an outcome of interest that we are trying to predict\n\\(\\boldsymbol X\\): A vector of data points used to predict the outcome\n\\(f\\): An unknown function that predicts the outcome\n\\(\\boldsymbol \\theta\\): A vector of parameters to used to define the model"
  },
  {
    "objectID": "lectures/3a.html#what-is-going-on",
    "href": "lectures/3a.html#what-is-going-on",
    "title": "Neural Networks",
    "section": "What is going on?",
    "text": "What is going on?\n\nData helps buil in a model\nUses mathematical models to predict outcomes\nUses probability theory to model randomness and loss\nUses numerical algorithms to:\n\nFind numerical values of parameters that minimize randomness\nModel unknown and nonlinear relationships"
  },
  {
    "objectID": "lectures/3a.html#main-types-of-machine-learning",
    "href": "lectures/3a.html#main-types-of-machine-learning",
    "title": "Neural Networks",
    "section": "Main Types of Machine Learning",
    "text": "Main Types of Machine Learning\n\n\nSupervised Learning\n\nData includes inputs and outputs\nML Models learns to map inputs → outputs\n\n\nUnsupervised Learning\n\nData has no labels\nModel discovers hidden patterns"
  },
  {
    "objectID": "lectures/3a.html#linear-regression-1",
    "href": "lectures/3a.html#linear-regression-1",
    "title": "Neural Networks",
    "section": "Linear Regression",
    "text": "Linear Regression\nLinear Regression is a tool to predict continuous random variales that are known to follow a Normal Distribution, with a set of known predictor variables."
  },
  {
    "objectID": "lectures/3a.html#simple-linear-regression",
    "href": "lectures/3a.html#simple-linear-regression",
    "title": "Neural Networks",
    "section": "Simple Linear Regression",
    "text": "Simple Linear Regression\nSimple linear regression will model the association between one predictor variable and an outcome:\n\\[\n\\hat Y = \\beta_0 + \\beta_1 X\n\\]\n\n\\(\\beta_0\\): Intercept term\n\\(\\beta_1\\): Slope term"
  },
  {
    "objectID": "lectures/3a.html#mlr",
    "href": "lectures/3a.html#mlr",
    "title": "Neural Networks",
    "section": "MLR",
    "text": "MLR\nMultivariable linear regression models are used when more than one explanatory variable is used to explain the outcome of interest."
  },
  {
    "objectID": "lectures/3a.html#additional-continuous-variable",
    "href": "lectures/3a.html#additional-continuous-variable",
    "title": "Neural Networks",
    "section": "Additional Continuous Variable",
    "text": "Additional Continuous Variable\nTo fit additional variable to the model, we will only need to add it to the model:\n\\[\n\\hat Y = \\beta_0 +\\beta_1 X_{1} + \\beta_2 X_{2}\n\\]"
  },
  {
    "objectID": "lectures/3a.html#categorical-variable",
    "href": "lectures/3a.html#categorical-variable",
    "title": "Neural Networks",
    "section": "Categorical Variable",
    "text": "Categorical Variable\nA categorical variable can be included in a model, but a reference category must be specified."
  },
  {
    "objectID": "lectures/3a.html#fitting-a-model-with-categorical-variables",
    "href": "lectures/3a.html#fitting-a-model-with-categorical-variables",
    "title": "Neural Networks",
    "section": "Fitting a model with categorical variables",
    "text": "Fitting a model with categorical variables\nTo fit a model with categorical variables, we must utilize dummy (binary) variables that indicate which category is being referenced. We use \\(C-1\\) dummy variables where \\(C\\) indicates the number of categories. When coded correctly, each category will be represented by a combination of dummy variables."
  },
  {
    "objectID": "lectures/3a.html#example",
    "href": "lectures/3a.html#example",
    "title": "Neural Networks",
    "section": "Example",
    "text": "Example\nIf we have 4 categories, we will need 3 dummy variables:\n\n\n\n\nCat 1\nCat 2\nCat 3\nCat 4\n\n\n\n\nDummy 1\n1\n0\n0\n0\n\n\nDummy 2\n0\n1\n0\n0\n\n\nDummy 3\n0\n0\n1\n0\n\n\n\nWhich one is the reference category?"
  },
  {
    "objectID": "lectures/3a.html#model-with-categorical-variables",
    "href": "lectures/3a.html#model-with-categorical-variables",
    "title": "Neural Networks",
    "section": "Model with categorical variables",
    "text": "Model with categorical variables\nFitting an additional variable with 4 Categories\n\\[\n\\hat Y = \\beta_0 +\\beta_1 X_{1} + \\beta_2 X_{2} + \\beta_3 D_{1} + \\beta_4 D_{2} + \\beta_5  D_{3}\n\\]"
  },
  {
    "objectID": "lectures/3a.html#sums-of-squared-errors",
    "href": "lectures/3a.html#sums-of-squared-errors",
    "title": "Neural Networks",
    "section": "Sums of Squared Errors",
    "text": "Sums of Squared Errors\nWe find the values of \\(\\beta_1, \\cdots, \\beta_5\\) that minimizes the following function for \\(i\\) data points:\n\\[\nRSS = \\sum^n_{i=1}(Y_i-\\hat Y_i)^2\n\\]"
  },
  {
    "objectID": "lectures/3a.html#matrix-formulation",
    "href": "lectures/3a.html#matrix-formulation",
    "title": "Neural Networks",
    "section": "Matrix Formulation",
    "text": "Matrix Formulation\n\\[\nY_i = \\boldsymbol X_i^\\mathrm T \\boldsymbol \\beta + \\epsilon_i\n\\]\n\n\\(Y_i\\): Outcome Variable\n\\(\\boldsymbol X_i\\): Predictors\n\\(\\boldsymbol \\beta\\): Coefficients\n\\(\\epsilon_i\\): error term"
  },
  {
    "objectID": "lectures/3a.html#matrix-data-formulation",
    "href": "lectures/3a.html#matrix-data-formulation",
    "title": "Neural Networks",
    "section": "Matrix Data Formulation",
    "text": "Matrix Data Formulation\n\\[\n\\boldsymbol\\beta = (\\boldsymbol X^\\mathrm T \\boldsymbol X)^{-1} \\boldsymbol X^\\mathrm T \\boldsymbol Y\n\\]"
  },
  {
    "objectID": "lectures/3a.html#neural-networks-1",
    "href": "lectures/3a.html#neural-networks-1",
    "title": "Neural Networks",
    "section": "Neural Networks",
    "text": "Neural Networks\nNeural networks are a type of machine learning algorithm that are designed to mimic the function of the human brain. They consist of interconnected nodes or “neurons” that process information and generate outputs based on the inputs they receive."
  },
  {
    "objectID": "lectures/3a.html#uses",
    "href": "lectures/3a.html#uses",
    "title": "Neural Networks",
    "section": "Uses",
    "text": "Uses\nNeural networks are typically used for tasks such as image recognition, natural language processing, and prediction. They are capable of learning from data and improving their performance over time, which makes them well-suited for complex and dynamic problems."
  },
  {
    "objectID": "lectures/3a.html#neural-network",
    "href": "lectures/3a.html#neural-network",
    "title": "Neural Networks",
    "section": "Neural Network",
    "text": "Neural Network"
  },
  {
    "objectID": "lectures/3a.html#neural-network-composition",
    "href": "lectures/3a.html#neural-network-composition",
    "title": "Neural Networks",
    "section": "Neural Network Composition",
    "text": "Neural Network Composition\n\nInputs: A set of characteristics in the data that we use to predict the outcome of interest\nOutputs: A set of variables (may be one) we wish to predict\nHidden Layers: A set of functions that will transform the data such that it can better predict the outputs\n\nEach hidden layer will has nodes that indicates the transformation"
  },
  {
    "objectID": "lectures/3a.html#single-layer-neural-network",
    "href": "lectures/3a.html#single-layer-neural-network",
    "title": "Neural Networks",
    "section": "Single Layer Neural Network",
    "text": "Single Layer Neural Network"
  },
  {
    "objectID": "lectures/3a.html#model-setup",
    "href": "lectures/3a.html#model-setup",
    "title": "Neural Networks",
    "section": "Model Setup",
    "text": "Model Setup\n\\[\nY = f(\\boldsymbol X; \\boldsymbol \\theta)\n\\]\n\n\\(\\boldsymbol X\\): a vector of predictor variables\n\\(\\boldsymbol \\theta\\): a vector of parameters (\\(\\boldsymbol \\beta, \\boldsymbol \\alpha\\))"
  },
  {
    "objectID": "lectures/3a.html#single-layer-neural-networks",
    "href": "lectures/3a.html#single-layer-neural-networks",
    "title": "Neural Networks",
    "section": "Single Layer Neural Networks",
    "text": "Single Layer Neural Networks\nA single layer neural networks can be formulated as linear function:\n\\[\nf(\\boldsymbol X; \\boldsymbol \\theta) = \\beta_0 + \\sum^K_{k=1}\\beta_kh_k(\\boldsymbol X)\n\\]\nWhere \\(X\\) is a vector of inputs of length \\(p\\) and \\(K\\) is the number of nodes (neurons), \\(\\beta_j\\) are parameters\n\\[\nh_k(\\boldsymbol X) = g\\left(\\alpha_{k0} + \\sum^p_{l=1}\\alpha_{kl}X_{l}\\right)\n\\]\nwith \\(g(\\cdot)\\) being a nonlinear activation function and \\(\\alpha_{kl}\\) are the weights (parameters)."
  },
  {
    "objectID": "lectures/3a.html#fitting-a-neural-network",
    "href": "lectures/3a.html#fitting-a-neural-network",
    "title": "Neural Networks",
    "section": "Fitting a Neural Network",
    "text": "Fitting a Neural Network\nFitting a neural network is the process of taking input data (\\(X\\)), finding the numerical values for the paramters that will minimize the following loss function, mean squared errors (MSE):\n\\[\n\\frac{1}{n}\\sum^n_{i-1}\\left\\{Y_i-f(\\boldsymbol X; \\boldsymbol \\theta)\\right\\}^2\n\\]"
  },
  {
    "objectID": "lectures/3a.html#nonlinear-activations-function-gcdot",
    "href": "lectures/3a.html#nonlinear-activations-function-gcdot",
    "title": "Neural Networks",
    "section": "Nonlinear (Activations) Function \\(g(\\cdot)\\)",
    "text": "Nonlinear (Activations) Function \\(g(\\cdot)\\)\nActivation functions are used to create a nonlinear affect within the neural network. Common activation functions are\n\nSigmoidal: \\(g(z) = \\frac{1}{1+e^{-z}}\\) (nn_sigmoidal)\nReLU (rectified linear unit): \\(g(z) = (z)_+ = zI(z\\geq0)\\) (nn_relu)\nHyperbolic Tangent: \\(g(z) = \\frac{\\sinh(z)}{\\cosh(z)} = \\frac{\\exp(z) - \\exp(-z)} {\\exp(z) + \\exp(-z)}\\) (nn_tanh)\n\nOtherwise, the neural network is just an overparameterized linear model."
  },
  {
    "objectID": "lectures/3a.html#optimizer",
    "href": "lectures/3a.html#optimizer",
    "title": "Neural Networks",
    "section": "Optimizer",
    "text": "Optimizer\nThe optimizer is the mathematical algorithm used to find the numerical values for the parameters \\(\\beta_j\\) and \\(\\alpha_{kl}\\).\n\nThe most basic algorithm used in gradient descent."
  },
  {
    "objectID": "lectures/3a.html#penguin-data",
    "href": "lectures/3a.html#penguin-data",
    "title": "Neural Networks",
    "section": "Penguin Data",
    "text": "Penguin Data\n\nDescriptionData Prep\n\n\nBuild a single-layer neural network that will predict body_mass with the remaining predictors. The hidden layer will contain 20 nodes, and the activation functions will be ReLU.\n\n\n\nlibrary(tidyverse)\npenguins &lt;- penguins |&gt; drop_na()\npx &lt;- penguins |&gt;\n  model.matrix(body_mass ~ . - 1, data = _) |&gt; \n  scale() |&gt; \n  torch_tensor(dtype = torch_float())\n\npy &lt;- penguins |&gt; \n  select(body_mass) |&gt; \n  as.matrix() |&gt; \n  torch_tensor(dtype = torch_float())"
  },
  {
    "objectID": "lectures/3a.html#model-description",
    "href": "lectures/3a.html#model-description",
    "title": "Neural Networks",
    "section": "Model Description",
    "text": "Model Description\n\nOverallInitializeForward\n\n\n\nmodnn &lt;- nn_module(\n  initialize = function(input_size) {\n    self$hidden &lt;- nn_linear(input_size, 20)\n    self$activation &lt;- nn_relu()\n    self$output &lt;- nn_linear(20, 1)\n  },\n  forward = function(x) {\n    x |&gt; \n      self$hidden() |&gt;  \n      self$activation() |&gt;  \n      self$output()\n  }\n)\n\n\n\nCreates the functions needed to describe the details of each network.\n\ninitialize = function(input_size) {\n    self$hidden &lt;- nn_linear(input_size, 50)\n    self$activation &lt;- nn_relu()\n    self$output &lt;- nn_linear(50, 1)\n  }\n\n\n\nModels the neural network.\n\nforward = function(x) {\n    x |&gt; \n      self$hidden() |&gt;  \n      self$activation() |&gt;  \n      self$output()\n  }"
  },
  {
    "objectID": "lectures/3a.html#optimizer-set-up",
    "href": "lectures/3a.html#optimizer-set-up",
    "title": "Neural Networks",
    "section": "Optimizer Set Up",
    "text": "Optimizer Set Up\n\nmodnn &lt;- modnn |&gt; \n  setup(\n    loss = nn_mse_loss(), # Used for numerical counts\n    optimizer = optim_rmsprop\n  ) |&gt;\n  set_hparams(input_size = ncol(px))"
  },
  {
    "objectID": "lectures/3a.html#fit-a-model",
    "href": "lectures/3a.html#fit-a-model",
    "title": "Neural Networks",
    "section": "Fit a Model",
    "text": "Fit a Model\n\nFitPlot\n\n\n\nfitted &lt;- modnn |&gt; \n  fit(\n    data = list(px, py),\n    epochs = 200 # Can think as number of iterations\n  )\n\n\n\n\n\nCode\nplot(fitted)"
  },
  {
    "objectID": "lectures/3a.html#error-rate",
    "href": "lectures/3a.html#error-rate",
    "title": "Neural Networks",
    "section": "Error Rate",
    "text": "Error Rate\nWhen creating a model, we are interested in determining how effective the model will be in predicting a new data point, ie not in our training data.\n\nThe error rate is a metric to determine how often will future data points be when using our model.\n\n\nThe problem is how can we get future data to validate our model?"
  },
  {
    "objectID": "lectures/3a.html#trainingvalidatingtesting-data-1",
    "href": "lectures/3a.html#trainingvalidatingtesting-data-1",
    "title": "Neural Networks",
    "section": "Training/Validating/Testing Data",
    "text": "Training/Validating/Testing Data\nThe Training/Validating/Testing Data set is a way to take the original data set and split into 3 seperate data sets: training, validating, and testing.\n\nTrainingValidatingTesting\n\n\nThis is data used to create the model.\n\n\nThis is data used to evaluate the data during it’s creation. It is evaluate at each Iteration (Epoch)\n\n\nThis is data used to test the final model and compute the error rate."
  },
  {
    "objectID": "lectures/3a.html#training-error-rate",
    "href": "lectures/3a.html#training-error-rate",
    "title": "Neural Networks",
    "section": "Training Error Rate",
    "text": "Training Error Rate\nTraining Error Rate is the error rate of the data used to create the model of interest. It describes how well the model predicts the data used to construct it."
  },
  {
    "objectID": "lectures/3a.html#test-error-rate",
    "href": "lectures/3a.html#test-error-rate",
    "title": "Neural Networks",
    "section": "Test Error Rate",
    "text": "Test Error Rate\nTest Error Rate is the error rate of predicting a new data point using the current established model."
  },
  {
    "objectID": "lectures/3a.html#penguin-data-1",
    "href": "lectures/3a.html#penguin-data-1",
    "title": "Neural Networks",
    "section": "Penguin Data",
    "text": "Penguin Data\n\nTrain/Test/EvaluationTrainingValidateTesting\n\n\n\npenguins &lt;- penguins |&gt; drop_na()\ntraining &lt;- penguins |&gt; slice_sample(prop = .8)\npre &lt;- penguins |&gt; anti_join(training)\nvalidate &lt;- pre |&gt; slice_sample(prop =  0.5)\ntesting &lt;- pre |&gt; anti_join(validate)\n\n\n\n\nXtraining &lt;- training |&gt; \n  model.matrix(body_mass ~ . - 1, data = _) |&gt; \n  scale() |&gt; \n  torch_tensor(dtype = torch_float())\n\nYtraining &lt;- training |&gt; \n  select(body_mass) |&gt; \n  as.matrix() |&gt; \n  torch_tensor(dtype = torch_float())\n\n\n\n\nXvalidate &lt;- validate |&gt; \n  model.matrix(body_mass ~ . - 1, data = _) |&gt; \n  scale() |&gt; \n  torch_tensor(dtype = torch_float())\n\nYvalidate &lt;- validate |&gt; \n  select(body_mass) |&gt; \n  as.matrix() |&gt; \n  torch_tensor(dtype = torch_float())\n\n\n\n\nXtesting &lt;- testing |&gt; \n  model.matrix(body_mass ~ . - 1, data = _) |&gt; \n  scale() |&gt; \n  torch_tensor(dtype = torch_float())\n\nYtesting &lt;- testing |&gt; \n  select(body_mass) |&gt; \n  as.matrix() |&gt; \n  torch_tensor(dtype = torch_float())"
  },
  {
    "objectID": "lectures/3a.html#model-description-1",
    "href": "lectures/3a.html#model-description-1",
    "title": "Neural Networks",
    "section": "Model Description",
    "text": "Model Description\n\nmodnn &lt;- nn_module(\n  initialize = function(input_size) {\n    self$hidden &lt;- nn_linear(input_size, 20)\n    self$activation &lt;- nn_relu()\n    self$output &lt;- nn_linear(20, 1)\n  },\n  forward = function(x) {\n    x |&gt; \n      self$hidden() |&gt;  \n      self$activation() |&gt;  \n      self$output()\n  }\n)"
  },
  {
    "objectID": "lectures/3a.html#optimizer-set-up-1",
    "href": "lectures/3a.html#optimizer-set-up-1",
    "title": "Neural Networks",
    "section": "Optimizer Set Up",
    "text": "Optimizer Set Up\n\nmodnn &lt;- modnn |&gt; \n  setup(\n    loss = nn_mse_loss(), # Used for numerical counts\n    optimizer = optim_rmsprop\n  ) |&gt;\n  set_hparams(input_size = ncol(px))"
  },
  {
    "objectID": "lectures/3a.html#fit-a-model-1",
    "href": "lectures/3a.html#fit-a-model-1",
    "title": "Neural Networks",
    "section": "Fit a Model",
    "text": "Fit a Model\n\nFitPlotTesting ModelThursday\n\n\n\nfitted &lt;- modnn |&gt; \n  fit(\n    data = list(Xtraining, Ytraining),\n    epochs = 200, # Can think as number of iterations\n    valid_data = list(Xvalidate, Yvalidate)\n  )\n\n\n\n\n\nCode\nplot(fitted)\n\n\n\n\n\nPredictionMAEPlot\n\n\n\nnpred &lt;- predict(fitted, Xtesting)\n\n\n\n\nmean(abs(as.matrix(Ytesting) - as.matrix(npred)))\n\n\n\n\n\nCode\nplot(as.matrix(Ytesting), as.matrix(npred),\n     xlab = \"Truth\",\n     ylab = \"Predicted\")\n\n\n\n\n\n\nThursday\n\n\n\nMachine Learning\n\n\nLinear Regression\n\n\nNeural Networks\n\n\nOther Topics\n\n\nSingle-Layer Neural Network in R\n\n\nTraining/Validating/Testing Data\n\n\nThursday\n\n\n\n\n\n\n\nCome perpared to work on your smart goal.\nShow evidence, either by submitting a word document, notebook, or other format, that you accomplished last week’s smart goal."
  },
  {
    "objectID": "posts/week_1.html",
    "href": "posts/week_1.html",
    "title": "Week 1",
    "section": "",
    "text": "Welcome to the course!\n\n\n\n\n\nInstalling R and RStudio\nScripts\nR Calculator\nR Objects\nR Packages"
  },
  {
    "objectID": "posts/week_1.html#learning-outcomes",
    "href": "posts/week_1.html#learning-outcomes",
    "title": "Week 1",
    "section": "",
    "text": "Welcome to the course!\n\n\n\n\n\nInstalling R and RStudio\nScripts\nR Calculator\nR Objects\nR Packages"
  },
  {
    "objectID": "posts/week_1.html#resources",
    "href": "posts/week_1.html#resources",
    "title": "Week 1",
    "section": "Resources",
    "text": "Resources\n\n\n\nLecture\nSlides\nVideos\n\n\n\n\n1\nSlides\nNA\n\n\n2\nSlides\nNA"
  },
  {
    "objectID": "posts/week_3.html",
    "href": "posts/week_3.html",
    "title": "Week 3",
    "section": "",
    "text": "Welcome to the course!\n\n\n\n\n\nInstalling R and RStudio\nScripts\nR Calculator\nR Objects\nR Packages"
  },
  {
    "objectID": "posts/week_3.html#learning-outcomes",
    "href": "posts/week_3.html#learning-outcomes",
    "title": "Week 3",
    "section": "",
    "text": "Welcome to the course!\n\n\n\n\n\nInstalling R and RStudio\nScripts\nR Calculator\nR Objects\nR Packages"
  },
  {
    "objectID": "posts/week_3.html#resources",
    "href": "posts/week_3.html#resources",
    "title": "Week 3",
    "section": "Resources",
    "text": "Resources\n\n\n\nLecture\nSlides\nVideos\n\n\n\n\n1\nSlides\nNA\n\n\n2\n\nNA"
  }
]